0.00 15.24 "Анатолий Кулаков" Здравствуйте, дорогие друзья, в эфире Radio.net, летний выпуск девяносто седьмой, в эфире жарких студий Анатолий
15.24 18.60 "Игорь Лабутин" Кулаков и Игорь Лабутин, всем привет.
18.60 27.24 "Анатолий Кулаков" Спасибо вам за помощь всем, кто шарит, репостит, комментирует наши выпуски, а именно нашим блестящим помогаторам, которые не оставляют нас одних на бусте.
27.24 43.92 "Анатолий Кулаков" Среди них Александр, Сергей, Владислав, Шевченко Антон, Лазарев Илья, Гурий Самарин, Виктор, Руслан Артамонов, Александр Ерыгин, Сергей Бензенко, Александр Лапердин, Ольга Бондаренко, Дмитрий Сорокин, Сергей Краснов, Константин Ушаков, Андрей Фазлеев, Басим Альджавахири, Андрей Маслов.
43.92 49.28 "Анатолий Кулаков" Друзья, всем большое спасибо, кто нас поддерживает, а также всех тех, кто, пожалуй, остался неизвестными.
49.28 55.96 "Анатолий Кулаков" И заходите к нам на бусте и посмотрите, что там интересно можно предложить для вас, если вдруг вы еще не с нами.
55.96 61.76 "Анатолий Кулаков" Ну что ж, а мы сегодня продолжим информировать вас о самых интересных новостях и об увлекательных статьях.
61.76 66.56 "Анатолий Кулаков" Из новостей, наверное, немного, самая яркая новость это то, что у нас вышел новый превью.
66.56 73.88 "Игорь Лабутин" Да, превью вышел, это превью номер 4, и надо сказать, что с одной стороны статья получилась...
73.88 76.36 "Анатолий Кулаков" Подожди, почему 4, превью номер 6 вышел.
76.36 86.52 "Игорь Лабутин" Действительно, превью номер 6, вероятно, там кажется, что настолько мало всего накапливается, что кажется, что хватило бы только на 4 превью, но их растянули на 6.
86.52 87.52 "Игорь Лабутин" Статья...
87.52 92.52 "Игорь Лабутин" Статьи, точнее, а если быть еще более точным, то дискашены или кто они?
92.52 93.52 "Игорь Лабутин" Сейчас ищешь на GitHub, да?
93.52 95.40 "Игорь Лабутин" Вот эта вот дурацкая система, как мне кажется.
95.40 98.12 "Анатолий Кулаков" Да, там, на смысле, дискашенсы выищутся.
98.12 99.12 "Игорь Лабутин" Вот.
99.12 107.64 "Игорь Лабутин" На GitHub мне, когда я готовился, казалось, что там, ух, много-много-много-много, а по факту что-то как-то оказалось важного не так-то и много.
107.64 109.32 "Игорь Лабутин" Но давайте пробежимся по порядку.
109.32 111.08 "Игорь Лабутин" Начнем с библиотек.
111.08 118.12 "Игорь Лабутин" В библиотеках, там какой-то прям огромный упор на пакет под названием System Numerics.
118.12 121.08 "Игорь Лабутин" Напомню, это пакет, в котором лежат всяческие...
121.08 122.36 "Игорь Лабутин" Namespace, да?
122.36 126.48 "Игорь Лабутин" В котором лежат всяческие разные типы, относящиеся к математике.
126.48 138.36 "Игорь Лабутин" Там лежит BigInteger, там лежит викторизация всякая, и вот как раз-таки в BigInteger ограничили количество символов, цифр, точнее, если быть более точным, битов.
138.36 140.72 "Игорь Лабутин" То есть у BigInteger раньше не было лимита.
140.72 143.84 "Анатолий Кулаков" Да, я всегда надеялся, что он бесконечный, всегда
143.84 144.84 "Игорь Лабутин" так было.
144.84 147.60 "Игорь Лабутин" Ну вот теперь он не бесконечный, теперь у него есть верхний лимит.
147.60 150.28 "Игорь Лабутин" Ты ему не можешь туда запихать больше, чем 2 миллиарда битов.
150.28 153.88 "Анатолий Кулаков" Да что ж за беспредел, что это такое, совместимость с калькуляторами, что ли?
153.88 168.20 "Игорь Лабутин" Ну, как они сказали, что именно на таких объемах как бы стандартный .NET BigInteger ведёт себя плюс-минус нормально, а если вам нужно больше, ну вам явно что-то нужно кастомное, лучше напишите кастомное и используйте наш.
168.20 169.20 "Игорь Лабутин" Короче, теперь работать не будет.
169.20 170.20 "Игорь Лабутин" Дальше.
170.20 191.08 "Игорь Лабутин" Добавили API под названием BigMult, ну в смысле BigMultiplication, и это, наверное, ну не то чтобы отменит, но по крайней мере повлияет на часть вопросов на собеседованиях, когда спрашивают, как нужно умножать int на int, да, с учётом переполнения, вот это всё, да, что будет, когда их умножить.
191.08 198.44 "Игорь Лабутин" Короче, теперь есть API, которая принимает 2 int, возвращает long, или которая принимает 2 long и возвращает int 128, ну и так далее.
198.44 202.56 "Игорь Лабутин" Вот, так что если вы теперь умножаете, вот можно это делать теперь безопасно этой штукой.
202.56 207.96 "Анатолий Кулаков" Да, хороший ответ, главное его как бы запомнить и узнать, с какой версии он доступен.
207.96 208.96 "Игорь Лабутин" Да-да-да.
208.96 235.32 "Игорь Лабутин" Также появилось некоторый conversion APIs для векторов, то есть если вы хотите сконвертировать, например, какой-нибудь там, не знаю, вектор размера 3 или там 4 в quaternion, что тоже является по сути вектором размера 4, то это теперь будет zero cost operation, ну то есть это не будет требовать никакого реальной конвертации, он просто это, скастует объект один к одному, втруг-втруг, ну, будет считать другим типом и всё будет хорошо, вот.
235.32 247.56 "Игорь Лабутин" Ну и появилось создание API, что-то мне казалось, что раньше было, вектор create APIs для вектор t, вектор 2, вектор 3, вектор 4, но вот сказали, что что-то новое добавили.
247.56 248.56 "Игорь Лабутин" Ну, добавили и добавили.
248.56 252.28 "Игорь Лабутин" Я как-то векторизацией не занимаюсь, поэтому не знаю, что там происходит.
252.28 254.48 "Игорь Лабутин" Дальше из библиотек.
254.48 261.00 "Игорь Лабутин" Следующий кусочек — это штука под названием поддержка primary конструкторов в logging source-генераторе.
261.00 274.00 "Игорь Лабутин" То есть если вы берёте класс, в этом классе объявляете primary конструктор, и у него есть partial метод, в котором вы задаёте атрибут logger message, то раньше это не работало.
274.00 275.00 "Игорь Лабутин" Не сапто.
275.00 284.64 "Игорь Лабутин" Потому что, ну, logger message — атрибут, напомню, что он там source-генерирует соответствующую добавку, которая должна ссылаться на тот ilogger, который у вас есть в классе.
284.64 287.92 "Игорь Лабутин" Но вот если это был primary конструктор, то он не понимал, что он там есть.
287.92 291.84 "Игорь Лабутин" Ну, такой мелкий как бы недочёт, но вот это пофиксили.
291.84 295.36 "Игорь Лабутин" В System Text JSON появилось довольно много штук.
295.36 297.96 "Игорь Лабутин" Во-первых, теперь есть JSON-схема exporter.
297.96 304.84 "Игорь Лабутин" Она позволяет заэкспортировать JSON-схему для .NET типа.
304.84 312.44 "Игорь Лабутин" Вероятно, эта штука была нужна для какого-нибудь OpenAPI-генератора или что-то подобного, и поэтому теперь она есть в виде публичного типа.
312.44 316.12 "Игорь Лабутин" То есть у JSON-схемы экспортера есть такой класс.
316.12 327.52 "Игорь Лабутин" Есть теперь метод, который называется getJSONSchemaAsNode, которое возвращает, собственно, описание JSON-чика по заданному типу.
327.52 328.52 "Игорь Лабутин" Можно теперь так.
328.52 331.32 "Анатолий Кулаков" Ну, это полезно, полезно, в принципе, схемы давно
331.32 332.32 "Игорь Лабутин" не хватает.
332.32 337.64 "Игорь Лабутин" Ну, я пока не могу придумать, зачем это мне, может быть, надо в обычном коде, но, вот я говорю, OpenAPI, скорее всего, это используют их собственные.
337.64 341.20 "Игорь Лабутин" Напомню, что они же отказались от свеш-бакла и пишут свой собственный OpenAPI-генератор.
341.20 343.52 "Игорь Лабутин" Мы сейчас про это поговорим немножко позднее.
343.52 344.68 "Игорь Лабутин" Вот, видимо, для этого и нужно.
344.68 351.08 "Игорь Лабутин" System.txt.json — интересный заголовок, меня он сначала даже поставил в тупик.
351.08 352.08 "Игорь Лабутин" Он называется respecting nullable annotations.
352.08 355.92 "Игорь Лабутин" То есть раньше System.txt.json вообще не смотрел на nullable аннотации, теперь смотрит.
355.92 360.56 "Игорь Лабутин" И теперь он может быть сконфигурен для того, чтобы это дело enforce-ить.
360.56 361.56 "Игорь Лабутин" Эти самые annotations.
361.56 365.68 "Игорь Лабутин" Для этого нужно включить флаг respect nullable annotations
365.68 367.68 "Анатолий Кулаков" и… Который по умолчанию выключен, да?
367.68 368.68 "Анатолий Кулаков" Да, ага.
368.68 369.68 "Анатолий Кулаков" Прикинь.
369.68 370.68 "Игорь Лабутин" Ну, для обратной совместимости, наверное.
370.68 371.68 "Игорь Лабутин" Видимо, да-да-да.
371.68 380.80 "Игорь Лабутин" И либо можно его включить через feature-switch, через ваши MS-билдовые пропертии под названием System.txt.json json-serializer-options-respect-nullable-annotations.
380.80 383.80 "Игорь Лабутин" Ну и тогда он начнет учитывать эти самые nullable аннотации.
383.80 391.64 "Игорь Лабутин" Если у вас есть non-nullable типа и в JSON-чике нету какого-то поля, соответствующего этому типу, ну, пропертий с этим типом, то это будет ошибкой десериализации.
391.64 399.44 "Игорь Лабутин" Так, а, и туда же поддержка non-optional constructor-parameters.
399.44 419.32 "Игорь Лабутин" То есть раньше, если у вас есть параметры конструктора, которые являются фактически обязательными, ну, например, это ваш единственный primary конструктор, да, и он инициализирует какие-нибудь там init-only свойства, то есть если вы не зададите такой параметр в конструкторе, вы, по сути, объект не можете создать.
419.32 420.96 "Игорь Лабутин" А раньше это дело и игнорилось.
420.96 429.56 "Игорь Лабутин" Вот, теперь все это нормально, можно опять же включить, называется respect-required-constructor-parameters-flag, тоже можно включить через feature-switch.
429.56 445.48 "Игорь Лабутин" Ну, и при этом вы можете менять, как они называются, requiredness, то есть свойство обязательности поля через отдельный атрибутик на свойстве, да, JSON-property-info.is-required.
445.48 456.28 "Игорь Лабутин" То есть, короче, явно потихонечку причесывают, причесывают, я бы сказал, System Text JSON, чтобы он со всеми новыми, совсем не такими новыми фичами дружил нормально.
456.28 474.60 "Анатолий Кулаков" Ну, слушай, вообще это довольно обидная штука, потому что поздновато, поздновато, и я в коде очень много встречал заблуждений таких, что люди децерализуют DTO-шки себе, проставляют им init-свойства и кричат, что эти init-свойства сериализатор сам проставит и проверит, иначе оно работать не будет.
474.60 484.60 "Анатолий Кулаков" Вот, а оказывается, что это только в будущей версии дотны это такое будет произойти, а уже люди написали, уже люди на null-reference-type рассчитывают, так что очень большое место для ошибок.
484.60 496.92 "Игорь Лабутин" Или наоборот, не рассчитывают, и тут такую фичу включат, ну, не знаю, кто-нибудь добрый напишет в глобальной директоре build-props на весь ваш продукт, а теперь включи такую фичу и полпродукта развалится, тоже вариант.
496.92 501.76 "Анатолий Кулаков" Нет, ну, я думаю, да, для старых продуктов такое включать в директоре build-props точно нельзя.
501.76 506.08 "Игорь Лабутин" Не, ну можно, но это отдельная фича с рефакторингом соответствующим.
506.08 511.28 "Анатолий Кулаков" Да блин, ты замучаешься все сценарии рефакторить, мало ли, какой там DTU еще тебе не присылали.
511.28 514.92 "Игорь Лабутин" Ну, а стопроцентное покрытие автотестами, что-то так не делаешь разве?
514.92 515.92 "Игорь Лабутин" Ха.
515.92 516.92 "Игорь Лабутин" Ну да.
516.92 517.92 "Игорь Лабутин" Ладно.
517.92 518.92 "Игорь Лабутин" Дальше.
518.92 540.28 "Игорь Лабутин" В JSON-обжекте, это объект классный, который позволяет вам работать с произвольным JSON внутри, появилась поддержка последовательности порядка свойств, т.е. вы, несмотря на то, что в целом, ну, в отличие от XML, JSON не то, что обычно рассчитывают, да, что свойства идут в определенном порядке.
540.28 551.84 "Анатолий Кулаков" Более того, у JSON на самом деле нет никаких свойств, потому что объекты со свойствами описываются синтезисом dictionary, т.е. на самом деле это dictionary, а у dictionary, как известно, ключи в непредсказуемом порядке.
551.84 569.80 "Игорь Лабутин" Все так, все так, но на самом деле, поскольку браузеры уже давно, так скажем, поддерживают расширение этого не то, что бы стандарта, но, да, договоренности про то, что на самом деле бывает такой порядок нужных свойств, я на это, кстати, с этим столкнулся в JavaScript местами.
569.80 581.52 "Игорь Лабутин" Один из плагинов Nginx на JavaScript как раз считал, что не надо поддерживать порядок свойств и там их сортировал в произвольном порядке.
581.52 582.52 "Игорь Лабутин" Вот.
582.52 589.08 "Игорь Лабутин" В принципе, он прав, но все сказали, блин, ну, ребята, все браузеры работают с учетом порядка, поэтому давайте будем работать с учетом порядка.
589.08 601.52 "Игорь Лабутин" Тотнет теперь тоже позволяет, вот здесь на нобочке теперь можно как раз через тот самый order dictionary работать с свойствами с учетом порядка, явного порядка, если вам вдруг зачем-то это надо.
601.52 602.52 "Игорь Лабутин" Но действительно, не советуем.
602.52 608.36 "Анатолий Кулаков" Смотри, это часто операция, допустим, те же самые роуты надо прописать, а роуты обрабатываются в каком-то порядке.
608.36 611.16 "Анатолий Кулаков" Если у тебя первый роут сработал, то остальные пускать не надо.
611.16 613.84 "Анатолий Кулаков" Или там исключения, или какие-нибудь фильтры.
613.84 618.68 "Анатолий Кулаков" У них у всех как бы по-хорошему должен быть порядок, вот ты пишешь несколько список рулов каких-нибудь.
618.68 624.72 "Игорь Лабутин" На самом деле, у меня задача была даже более простой, мне нужно было вывести список ключей в алфавитном порядке, чтобы тупо было проще искать.
624.72 625.72 "Игорь Лабутин" Вот.
625.72 646.64 "Игорь Лабутин" И даже, ну, то есть, моя попытка как бы, возьми все ключи, отсортируй и положи их обратно, вот в том JavaScript runtime, который использовал Nginx, там была какая-то старенькая версия, он как бы выдавал рандомный порядок, потому что операция сортировки как бы работала, но при записи обратно в JSON object никто не гарантировал порядок.
646.64 649.36 "Анатолий Кулаков" Ну, вот использовали листы, листы гарантируют порядок.
649.36 651.00 "Игорь Лабутин" Да-да-да-да, все так.
651.00 659.00 "Игорь Лабутин" Но там не на C#, нужно было все это еще обернуть все-таки в более объемистый JSON объектик, поэтому пришлось немножко попотеть.
659.00 660.60 "Игорь Лабутин" Ну, нормально, сработало все в итоге.
660.60 680.44 "Игорь Лабутин" И последнее, что добавили в persistent.json, называется это additional contract method data API, там есть на самом деле некоторые дополнительные атрибутики, которые позволяют вам, когда вы работаете с source-генератором, немножко больше знать про метаданные.
680.44 694.48 "Игорь Лабутин" Вот, сейчас не помню уже деталей, честно говоря, посмотрите, если вы пишете там source-генераторы для ваших контрактных, как это, source-генерируете что-нибудь на основе JSON-контрактов, ну тогда посмотрите.
694.48 695.48 "Игорь Лабутин" Вот.
695.48 699.92 "Игорь Лабутин" Мне кажется, что это не очень частая операция, но, возможно, нужно.
699.92 700.92 "Игорь Лабутин" Дальше.
700.92 713.52 "Игорь Лабутин" Я сегодня еще расскажу про C# 13, но если кратенько, там появились partial property, и, соответственно, тут же разрешили в .NET, в библиотеках, generated regex атрибут на property.
713.52 718.84 "Игорь Лабутин" То есть теперь не обязательно прям класс, метод точнее задавать, можно сделать property.
718.84 723.76 "Игорь Лабутин" И в regex добавилась еще одна важная штука, называется enumerate splits.
723.76 734.40 "Игорь Лабутин" Ну, всем, наверное, известна штука под названием string split, это функция, да, метод, который позволяет взять строчку, разделить ее по заданному разделителю и получить в ответ массив строчек.
734.40 741.92 "Игорь Лабутин" Все с ней хорошо, все замечательно, но она делит только по фиксированному количеству, ну, по фиксированным строкам, понятное дело.
741.92 753.96 "Игорь Лабутин" Есть соответствующий аналог, это regex .split, который позволяет взять строку, разделить по какому-то заданному regex на кусочки и вернуть, соответственно, массив строк.
753.96 754.96 "Игорь Лабутин" Но у него есть несколько недостатков.
754.96 764.40 "Игорь Лабутин" Во-первых, он принимает только строки, во-вторых, он аллоцирует, соответственно, массив строк в ответ, но и поскольку это массив строк, то каждый элемент это тоже зааллоцирована новая строка.
764.40 775.20 "Игорь Лабутин" В девятом .NET добавили новый метод, называется enumerate splits, который, во-первых, принимает спаны, а не только строчки, во-вторых, он возвращает enumerable из ренжей.
775.20 812.68 "Игорь Лабутин" То есть range, напомню, такая структура, которая по сути просто указатель начала, указатель, ну, точнее, индекс начала, индекс конца в оригинальном спане, по сути, и теперь вы можете, ничего не аллоцируя, делать regex split, то есть по regex сплитить ваши строчки без каких-то накладных расходов, особенно если учитывать, что regex умеют в source-генерированную версию, которая тоже будет, соответственно, достаточно оптимальной и почти ничего не аллоцировать, то все должно быть вообще прям зашибись и супер, если только ваш regex подходит для source-генерированной версии, там не все поддержано, насколько я помню.
812.68 829.68 "Игорь Лабутин" Так, про regex и все, про ordered dictionary я уже сказал, это новая коллекция, которая позволяет использовать, в отличие от dictionary, которая не гарантирует порядок ключей коллекции, ordered dictionary, соответственно, позволяет это делать.
829.68 840.80 "Игорь Лабутин" В принципе, такая коллекция была уже в дотнете давно, но она была не дженериковая, а поскольку мы сейчас все боремся за всякие memory и прочее, видимо, она где-то потребовалась в дженерик-версии, вот ее добавили, теперь она есть в дженерик-версии.
840.80 844.56 "Игорь Лабутин" А еще в дженерик-версии появилась штука под названием read-only set.
844.56 857.12 "Игорь Лабутин" У нас уже была коллекция под названием read-only collection, это, по сути, в wrapper, да, над любым более-менее ilist'ом от t, но только делающий его read-only вариантом.
857.12 871.52 "Игорь Лабутин" Есть read-only dictionary, по сути, то же самое, только над обычным dictionary, но для set'ов ничего такого не было, теперь есть read-only set, соответственно, штука, которая позволяет обернуть любой i-set в коллекцию, которая будет только для чтения, не будет позволять себе менять.
871.52 889.48 "Игорь Лабутин" Так, дальше про constraint мы поговорим в секции про C# 13, collection lookup with spans, о, это такая очень очередная, мне кажется, очень нишевая фича, которая нужна там либо ASP, либо еще кому-то.
889.48 892.56 "Игорь Лабутин" Что это вообще такое?
892.56 932.60 "Игорь Лабутин" Значит, смотрите, обычно у нас бывает такая штука, что мы для какого-то performance, вместо того, чтобы вычислять те или иные значения, мы их кэшируем в каком-нибудь либо словаре, либо кэшируем какой-то вычисленный там, не знаю, ключ, еще что-то в хэш-сете, чтобы потом быстро проверять, есть такое или нету, но в словаре и в хэш-сете, если вы работаете, например, с, к вам приходит точнее что-то, что является спаном, вы не можете спан проверить на присутствие в словаре, потому что словаре у вас, скорее всего, будет с ключами в виде стрингов, а спанами ключи сделать нельзя, потому что это рефстракт и вот это все.
932.60 961.80 "Игорь Лабутин" Соответственно, у dictionary теперь появился метод, который называется getAlternateLookup, который принимает, собственно, два типа, это key value исходного словаря, а также тип, чем вы собираетесь его лукапить, это readOnlySpan, в данном случае, например, если у вас был от стринга, то это будет readOnlySpan от чаров, и вот этот SpanLookup – это такой специальный класс, который позволяет лукапить через спаны.
961.80 976.00 "Игорь Лабутин" Какая-то очень супер-хай-перформанс штука, вероятно, связанная, подозреваю, что с каким-нибудь разбором заголовков в спанете или еще с чем-нибудь, потому что ноуш очень смахивает на эту штуку, я не знаю, зачем еще она, может быть полезна.
976.00 980.76 "Игорь Лабутин" Но, наверное, любители хай-перфоманс кода порадуются.
980.76 983.40 "Анатолий Кулаков" Ну да, какая-то очередная сверхоптимизация.
983.40 991.48 "Игорь Лабутин" Ну, слушай, по мелочам это нормально, просто когда только мелочи, вот это на самом деле печально.
991.48 1000.76 "Игорь Лабутин" То есть так-то штука, наверное, полезная и действительно найдутся любители или даже те, кому она очень нужна, но было бы нам еще что-нибудь более важное.
1000.76 1005.64 "Игорь Лабутин" Так, из еще менее важного появился новый класс, называется Base64URL.
1005.64 1018.00 "Игорь Лабутин" Ну, Base64 encoding у нас давно есть в Тотнете, есть метод конверта Base64String и прочие всякие, но проблема в том, что полученная строчка не является безопасной для урлов.
1018.00 1024.08 "Игорь Лабутин" Это потому что там есть знаки + и /, которые нельзя использовать в урлах, да, они требуют урл-энкодинга.
1024.08 1037.32 "Игорь Лабутин" Поэтому у нас есть RFC, на самом деле, как я выяснил, что-то я не знал об этом, что для кодировки Base64URL, где + и / заменены на минусы и подчеркивания, которые являются безопасными в урлах.
1037.32 1040.60 "Игорь Лабутин" Ну и, соответственно, теперь в Тотнете есть класс, который эту штуку поддерживает.
1040.60 1048.24 "Игорь Лабутин" Можно через Base64 кодировать что-нибудь в урлы, гарантированно на выходе будет то, что не нужно уже подвергать урл-энкодингу.
1048.24 1053.24 "Анатолий Кулаков" Так, это класс, который умеет конвертить туда-сюда или это вместо строки можно использовать?
1053.24 1054.24 "Игорь Лабутин" Да, туда-сюда.
1054.24 1055.24 "Анатолий Кулаков" Туда-сюда.
1055.24 1062.04 "Анатолий Кулаков" Не, ну просто у нас уже давно есть методы, которые умеют конвертировать Base64URL, они, ну я ими пользуюсь довольно часто, давно и много.
1062.04 1063.04 "Игорь Лабутин" Не в BCL.
1063.04 1064.04 "Игорь Лабутин" В BCL нету.
1064.04 1065.56 "Анатолий Кулаков" Ладно, сейчас пока поищу.
1065.56 1068.48 "Игорь Лабутин" Мне казалось, что, ну по крайней мере, статья говорит, что в BCL такого не было.
1068.48 1071.84 "Анатолий Кулаков" Да, да, они, скорее всего, в WSP.net были.
1071.84 1074.08 "Игорь Лабутин" Вот это может быть, хотя...
1074.08 1076.44 "Игорь Лабутин" То есть их, скорее всего, просто перенесли в BCL.
1076.44 1080.72 "Игорь Лабутин" Слушай, я вот не помню, я что-то не помню, что были, но, может быть, я давно этим не занимался.
1080.72 1086.64 "Игорь Лабутин" Мне что-то в Base64URL не надо было давно ничего кодировать, я как-то обходился, если надо, я просто кодировал урл-энкод и всё.
1086.64 1098.56 "Игорь Лабутин" У нас есть универсальные методы кодирования чего угодно в этот самый URL, ну, понятно, с эскейпингом, поэтому я обычно обходился, а в Base64 что-то как-то не надо было.
1098.56 1099.56 "Анатолий Кулаков" Ну ладно.
1099.56 1104.52 "Анатолий Кулаков" Кажется, что немножко не то, потому что урл-энкод ты, по-моему, байту передать не можешь, ты можешь только строчки передать.
1104.52 1108.24 "Анатолий Кулаков" А эту штуку ты прям массив байт отдаёшь, то есть любой бинарь можешь загнать в такой формат.
1108.24 1109.24 "Анатолий Кулаков" Ну вот...
1109.24 1110.24 "Игорь Лабутин" И это бывает часто удобно.
1110.24 1119.28 "Игорь Лабутин" За последние, М, не буду говорить, цать лет, не было надо ни разу, честно говоря, бинарь в Base64 запихать.
1119.28 1130.04 "Анатолий Кулаков" Ну вот, смотри, самый банальный пример, когда ты гуиды делаешь себе в виде идентификаторов, и они занимают большую-большую такую строчку, если их форматировать стандартным способом.
1130.04 1136.08 "Анатолий Кулаков" А вот если эти гуиды взять и загнать в Base64 урл, они превращаются в строчку во много раз меньше.
1136.08 1137.08 "Анатолий Кулаков" Ну не во много, погоди.
1137.08 1138.08 "Игорь Лабутин" Визуально приятнее.
1138.08 1139.08 "Игорь Лабутин" Не во много, а не раз меньше.
1139.08 1142.72 "Игорь Лабутин" Там всё равно 128 бит, которые всё равно нужно как-то упаковать, там всё равно меньше.
1142.72 1147.44 "Анатолий Кулаков" Ну как, у тебя там 16-ричная система, а здесь 64-ричная система.
1147.44 1148.44 "Анатолий Кулаков" Есть разница?
1148.44 1152.56 "Игорь Лабутин" Ну как бы не во много, там нет, ну раза в три может меньше.
1152.56 1153.56 "Игорь Лабутин" Ну это немного.
1153.56 1154.56 "Игорь Лабутин" Ладно.
1154.56 1155.56 "Игорь Лабутин" Да.
1155.56 1157.60 "Игорь Лабутин" Я передаю строчками, не парюсь.
1157.60 1158.60 "Игорь Лабутин" Вот.
1158.60 1162.24 "Игорь Лабутин" А то какие-то непонятные цифрыки, чиселки, вот это всё.
1162.24 1172.68 "Игорь Лабутин" Так, и появилась поддержка ServerSendEvents, и я, честно говоря, ни разу не работал с технологией ServerSendEvents, ничего не могу сказать, просто появилась новая библиотека.
1172.68 1173.68 "Игорь Лабутин" Вот.
1173.68 1179.40 "Игорь Лабутин" Поэтому, наверное, те, кто знает, что такое ServerSendEvents, они порадуются.
1179.40 1180.40 "Игорь Лабутин" Давай дальше.
1180.40 1181.40 "Игорь Лабутин" Дальше у нас Runtime.
1181.40 1187.88 "Игорь Лабутин" В кой-то веке у нас появилась секция про Runtime, на самом деле, по-моему, это чуть ли не первое превью, в котором что-то есть от Runtime.
1187.88 1194.16 "Игорь Лабутин" Про G, там какие-то штуки, потому что, по-моему, была полная тишина во всех прошлых превью, если я правильно помню.
1194.16 1195.16 "Игорь Лабутин" Ну так вот.
1195.16 1196.16 "Игорь Лабутин" Что у нас Runtime?
1196.16 1202.92 "Игорь Лабутин" И, во-первых, поменялось и улучшилось, ну, понятно, что у нас не то, что поменялось, у нас всё улучшилось, кодогенерация для ARM64.
1202.92 1211.36 "Игорь Лабутин" Выяснилось, ну, я выяснил, да, наверняка спецы это и так знают, что в ARM64 есть более оптимальные инструкции.
1211.36 1227.52 "Игорь Лабутин" То есть, грубо говоря, можно, если нужно сохранить регистры в память, да, можно вызвать команду "сохрани вот этот регистр в память", потом следующую "сохрани вот этот регистр в память", но в ARM64 есть команда "сохрани два регистра сразу в память", и если её использовать, ну, будет, если не в два раза быстрее, но чуть-чуть оптимальнее.
1227.52 1237.24 "Игорь Лабутин" Вот, короче, тотнет теперь научился использовать часть таких инструкций и стало, естественно, быстрее, на доли наносекунд, наверное, но быстрее.
1237.24 1250.40 "Игорь Лабутин" Дальше поменялось, вот это, может быть, как-то более будет важно, я, честно говоря, не смотрел какие-то выкладки по перформансу с точки зрения, там, какие мегапроценты оно приносит, возможно, потому что доли процента, не знаю, в статье не было.
1250.40 1266.72 "Игорь Лабутин" Это расположение кода, то есть при компиляции, когда метод компилируется, JIT'ом уже, понятное дело, не в момент компиляции компилятором, то у JIT'а есть цель сделать метод как можно более линейным.
1266.72 1272.56 "Игорь Лабутин" Понятное дело, потому что branch-переходы, ну, известно, давить в линии для процессора это не очень хорошо, особенно если оно непредсказуемое.
1272.56 1293.40 "Игорь Лабутин" Поэтому в идеале метод должен быть линейный, но код мы пишем нелинейно, понятно, что ифы есть, циклы есть, поэтому приходится JIT'у страдать и как-то всё это выравнивать, ну, в смысле, раскладывать в правильную максимально предсказуемую последовательность, в том смысле, что угадать, насколько максимальная вероятность того, что именно так пойдёт выполнение кода, ну или в большем количестве случаев.
1293.40 1306.64 "Игорь Лабутин" И вот теперь он стал использовать информацию о профайлинге, то есть раньше он не использовал информацию PGO про это дело, про File Guided Optimization, а только, ну, какие-то свои внутренние эвристики.
1306.64 1313.56 "Игорь Лабутин" Теперь это используют, ещё какие-то эвристики добавились и утверждается, что раскладка теперь прям, если не идеально, то гораздо лучше.
1313.56 1319.64 "Игорь Лабутин" Код должен работать быстрее и с меньшим количеством переходов.
1319.64 1338.68 "Игорь Лабутин" Оптимизация циклов — ещё один вопрос из разряда «а теперь это неактуально на собеседованиях» — может быть, слышал, да и, может, и сам спрашивал, не знаю, в докладах точно это встречалось, про то, что если ты пишешь цикл там от 0 до 10, это может быть медленнее, чем цикл от 10 до 0.
1338.68 1340.20 "Анатолий Кулаков" Да, да, было дело.
1340.20 1355.20 "Игорь Лабутин" Ну, потому что, как минимум, ассемблерная инструкция в конце, когда тебе нужно сравнить с 0, это, как правило, быстрее, чем сравнить не с 0, там что-нибудь откуда-нибудь загрузить, сравнить два регистра, вот это всё, ну, короче, там есть тонкости, почему к 0 быстрее.
1355.20 1366.24 "Игорь Лабутин" И вот теперь джит научился сам определять, когда разворачивание цикла будет безопасно для программы, не знаю, как он это делает, но как-то умеет, и если это безопасно, он сам развернёт цикл.
1366.24 1368.92 "Анатолий Кулаков" Чё-то уже страшно как бы становится.
1368.92 1369.92 "Игорь Лабутин" Ну вот, да.
1369.92 1372.36 "Игорь Лабутин" Будем считать в другую сторону, и всё автоматически.
1372.36 1377.12 "Игорь Лабутин" Не знаю, как определяет, что это безопасно, но как-то определяет.
1377.12 1387.48 "Игорь Лабутин" Я бы ещё поверил, что Рослинн может определить, ну, у него как бы больше информации, да, вот на уровне джита понять, что вот этот вот цикл, то есть либо это должны быть какие-нибудь очень простые циклы, ну, там не
1387.48 1388.48 "Анатолий Кулаков" знаю.
1388.48 1389.84 "Анатолий Кулаков" Типа сумма средняя, чё-нибудь такое.
1389.84 1402.92 "Игорь Лабутин" Ты знаешь, с суммой средним тоже не всё как бы просто, потому что если ты помнишь, например, есть такая тема, что сложение, допустим, вещественных чисел, да, нужно делать от больших к маленьким.
1402.92 1415.44 "Игорь Лабутин" Потому что если ты будешь сначала складывать маленькие, там накапливается ошибка, чё-то такое, и если у тебя вдруг, например, сортированный массив даблов в порядке убывания, и ты просто считаешь их сумму, то здесь разворачивать нельзя.
1415.44 1421.60 "Анатолий Кулаков" Не, мне кажется, что если там вещественные числа, то все оптимизации джита сразу надо выключать, потому что это грёбанная магия.
1421.60 1423.60 "Игорь Лабутин" Окей, да, тоже может быть.
1423.60 1429.84 "Игорь Лабутин" А ещё там у тебя нано где-нибудь в серединке воткнулся, и всё, и вся сумма идёт куда-нибудь не туда, становится наном сразу.
1429.84 1430.84 "Игорь Лабутин" Ну ладно.
1430.84 1439.96 "Игорь Лабутин" И последний, а нет, не последний, ещё тут есть всякие штуки avx10v1 support, и те, кто знает, что такое avx и что такое avx10, наверное, порадуются.
1439.96 1445.68 "Игорь Лабутин" Новый набор, я так понимаю, инструкции векторизации поддержанные от Intel.
1445.68 1452.44 "Игорь Лабутин" Так, кода генерации для intrinsиков, ну она, в принципе, и так была.
1452.44 1456.12 "Игорь Лабутин" Просто ещё больше расширили случаев, когда она чуть лучше работает.
1456.12 1468.04 "Игорь Лабутин" Ну и, вот ты говоришь, должны отключаться, когда floating point ты видишь, но нет, как раз появилась штука под названием constant folding, да, сворачивание констант для floating point и симдов.
1468.04 1476.60 "Игорь Лабутин" То есть если он понимает, что ты там, не знаю, векторно прибавляешь 0, то он это сделает нопом и не будет ничего делать.
1476.60 1477.60 "Игорь Лабутин" Такое.
1477.60 1479.76 "Анатолий Кулаков" Ну, для константа ладно, константу ещё можно как-то
1479.76 1480.76 "Игорь Лабутин" поверить.
1480.76 1481.76 "Игорь Лабутин" Да.
1481.76 1482.76 "Игорь Лабутин" Так, SDK.
1482.76 1486.72 "Игорь Лабутин" Мы потихонечку движемся к концу, не так много уже осталось.
1486.72 1492.72 "Игорь Лабутин" В SDK это несколько вещей поменялось, в основном связанных с аудитом и со сборкой.
1492.72 1496.72 "Игорь Лабутин" Значит, с аудитом мы уже рассказывали про штуку под названием Nuget Audit.
1496.72 1502.00 "Игорь Лабутин" По-моему, кстати, в прошлый раз или, наверное, не в прошлый, в прошлой статье были, в позапрошлый раз мы рассказывали про Nuget Audit.
1502.00 1515.08 "Игорь Лабутин" Это штука, ну новая как бы, режим работы, так скажем, не знаю, или кусочек системы сборки, система SDK рестора пакетов, которая позволяет проверить пакеты на уязвимости.
1515.08 1525.40 "Игорь Лабутин" По дефолту она работала раньше только для прямых зависимостей, то есть она проверяла прямые зависимости, а не проверяла транзитивные.
1525.40 1537.84 "Игорь Лабутин" Теперь, соответственно, поменялся дефолт, теперь она будет проверять и прямые, и транзитивные, но можно обратно вернуть только прямые, поставив правильную пропертию Nuget Audit Mode, нужное значение.
1537.84 1546.12 "Игорь Лабутин" Появилась новая команда, называется .NET NUGET Y.
1546.12 1556.68 "Игорь Лабутин" Когда я занимался проблемами, которые эта команда призвана решить, мне, наверное, правильнее казалось, что она должна называться .NET NUGET WTF, но пусть будет Y.
1556.68 1569.56 "Игорь Лабутин" Она позволяет, то есть вы ей задаете название дл или пакета, который вы видите, грубо говоря, у себя в аутпуте, она вам пишет, откуда он взялся из-за каких-то транзитивных зависимостей.
1569.56 1571.48 "Анатолий Кулаков" Да, очень мега полезная командка.
1571.48 1583.32 "Игорь Лабутин" Вот, то есть на самом деле и до этого можно было выяснить, потому что всё это дерево зависимости аккуратно пишется, как там он, package.log.json или что-то такое в аутпуте где-то, в интермидии от аутпути, по-моему, можно было поискать.
1583.32 1593.64 "Игорь Лабутин" Там есть файлик, где полное дерево зависимости, но оно такое сложное, большое, по нему искать неудобно, но оно как бы дерево нарисованное адской графикой, да.
1593.64 1607.06 "Игорь Лабутин" А здесь вот тебе по сути, я так понимаю, это грубо говоря, по этому дереву ищет короткий путь к корню, да, от заданной ноды, вот, ну, в принципе, то есть такой реализация, скорее всего, халявная, а пользы, на самом деле, много.
1607.06 1608.06 "Игорь Лабутин" Вот.
1608.06 1610.06 "Игорь Лабутин" И последняя штука называется msbuild.buildchecks.
1610.06 1615.48 "Игорь Лабутин" Короче, ростлина нам мало, у нас теперь будет новые анализаторы на уровне msbuild'а.
1615.48 1640.56 "Игорь Лабутин" Называется это buildchecks, и по мнению Microsoft они призваны заинфорсить еще больше правил, всяких инвариантов именно во время билдов, и цель не только ломать ваш билд, но и давать какие-то подсказки, ну, возможно, как-то что-то где-то говорить не просто, что вот билд сломан, а вот-вот, потому-то и потому-то.
1640.56 1673.24 "Игорь Лабутин" Пока добавлено всего два билдчека, билдчек номер один, это нельзя делать shared output path, то есть если у вас в солюшене несколько проектов, и у них у всех output или intermediate output указывает, ну не у всех, а хотя бы у двоих на одну и ту же территорию, это будет warning во время билда, номер bc0101, и, соответственно, второй warning - это если msbuild задетектирует, что вы один и тот же файл по какой-либо причине, не важно по какой, затираете в него в два раза, то это тоже будет warning, называется double write detection.
1673.24 1679.20 "Игорь Лабутин" То есть, в принципе, это обычно неправильно, и каждый файлик должен писаться во время билда один раз,
1679.20 1681.96 "Анатолий Кулаков" если вдруг он… То есть это русленый анализатор
1681.96 1688.88 "Игорь Лабутин" для msbuild? Ну, типа того, да, но только что без фиксеров автоматических, да, потому что… Это пока, наверное.
1688.88 1692.08 "Анатолий Кулаков" Прекрасно, если бы он показывал бы эти два места и сразу
1692.08 1714.92 "Игорь Лабутин" бы… Нет-нет, смотри, он показывает, то есть он говорит, что смотри, вот в этом там таргете вот здесь вот у тебя вот тут такая штука есть, типа оно вот overwritet вот тем-то, но я боюсь, что пока автоматически пофиксить с учётом всех там возможных супермегазависимости и, возможно, каких-то ещё там генерящихся дополнительно внешними тулами полускриптов для msbuild-а, хрен его знает, можно ли это сделать как-то фиксерами.
1714.92 1719.56 "Анатолий Кулаков" Ну, в общем… Да, ладно, слушай, даже если он покажет в условиях того тулинга, который есть
1719.56 1735.24 "Игорь Лабутин" у msbuild-а, это уже счастье. Ну, покажет, вообще, что покажет, посмотрим. Вот, и для того, чтобы это всё включить, нужно передать флажок analyze в любой тул, который, ну, грубо говоря, dotnet build, msbuild, куда угодно, если вы передадите флаж аналайз. Во все, короче.
1735.24 1747.16 "Игорь Лабутин" Да-да-да, везде, где дёргается msbuild, можно передать аналайз, и он, соответственно, вызывает эти самые build-чеки. Вот такая вот штука у нас в SDK появилась, посмотрим.
1747.16 1750.52 "Игорь Лабутин" Добавить хороший флажок. На сколько? Ну, ты уже перешёл
1750.52 1756.08 "Анатолий Кулаков" на девятое SDK? Нет, но я надеюсь, что флажок мне добавить никто не помешает, или он начнёт там ошибки
1756.08 1768.36 "Игорь Лабутин" вырисовывать. А, кстати, интересно, ты же действительно можешь передать… А я не знаю, кстати, я не помню, честно говоря, ругается ли msbuild на неизвестные ему флажки. Фиг его знает, кстати, не пробовал, вот, не передавал. Ладно, давай дальше.
1768.36 1884.80 "Игорь Лабутин" Последний кусочек – это asp.net core. Там, соответственно, добавились fingerprinting статических ассетов. По-моему, я про это уже где-то рассказывал, мне кажется. Или что-то они добавляли уже. А, они добавили кэширование и зимование, добавили ещё и fingerprinting. Соответственно, теперь они добавляют уникальный хэш контента к файлнейму, то есть если у вас лежит какой-нибудь там, не знаю, css-ник или js-файлик в статике, то при сборке он переименуется и в этот файлик допишется его чексума, грубо говоря, ну, хэш. Поскольку во многих местах вам нужно ссылаться на этот файлик по именам, ну, как бы там есть дальше некоторые моменты, как это сделать. В Blazor всё включено по умолчанию, для MVC и для Razor Pages нужно включать это через использование, вы должны использовать map_static_assets вместо use_static_files, ну и, соответственно, ещё позвать метод with_static_assets. В Blazor, соответственно, дальше нужно использовать proper_to_assets в ComponentBase для того, чтобы добраться до нужного файлика. И там есть индексер, куда вы передаёте исходное имя файла, он будет знать с какой чексумой за ним сходить. В MVC и Razor Pages там все вот эти вот тег-хелперы, они подкручены так, что вы ссылаетесь просто на имя файла, а он сам сходит за нужным. Для SignalARA завезли Distributed Tracing, теперь есть отдельный ActivitySource под названием Microsoft S/Panad Core SignalARA Server, и он там старается репортить ивенты для всех вызовов, соответственно, хаба, методов хаба. В OpenAPI появилось некоторое количество изменений. Во-первых, я что-то не знаю, по-моему, это первый раз, когда такое сделали Microsoft со словами, видимо, что что-то как-то наш этот новый OpenAPI не очень discoverable, сделали такую штуку.
1884.80 1930.44 "Игорь Лабутин" Я не знаю, это Roslyn делает или кто. Вы теперь, когда вы пишете, ну, что он говорит там, там, где вы должны написать useOpenAPI, это же extension метод, да, и теоретически он там должен появиться, и если у вас есть зарефинансированный NuGet пакет с этим самым OpenAPI кусочком. Так вот теперь, в студии, по крайней мере, вы можете писать, начать писать use, и он вам подскажет, что можно написать useOpenAPI, хотя вы еще пакет не зарефинансировали. Вы согласитесь с этим completion, он подчеркнется красным, и по тому hotkey, которым вы используете, значит, для того, чтобы это пофиксить, вам предложат, а давайте поставим пакет, который поддержит эту штуку. То есть такое, completion за тебя за неустановленные пакеты. Ну, нормальный шаг, нормальный.
1930.44 1937.28 "Анатолий Кулаков" Мне просто кажется, что надо пойти уже дальше, чтобы он в интеллисенсе сразу и пакет ставил, и на MSP подключал, и все сам делал. Ну, зачем эти все
1937.28 2043.28 "Игорь Лабутин" промежуточные шаги? Да-да-да, сейчас мы когда про студию поговорим в конце выпуска, там будет немножко про это. Дальше, для, если вы на параметрах ваших, ну, в смысле, на параметрах метода, либо на пропертях ваших DTO-шек используете attribute, required и default value, они, соответственно, будут переделаны в OpenAPI-схему, когда OpenAPI-схема генерируется. И еще добавили штуку под названием схема Transformers. То есть после того, как вы, после того, как автоматик изгенерирует вам JSON-схему OpenAPI, OpenAPI JSON-схему вашего IP, можно еще зарегистрировать нужное количество трансформеров, ну, через функцию OpenAPI-options, которые позволяют ее потом подредактировать на лету, что-нибудь добавить, что-нибудь расширить, там вот они, например, в примере, ну, там тупой пример, они просто дописывают какой-то там что-то типа автора и description, общий description на всю схему. Вот, но возможно вам сделать что-то более экзотическое, если надо. Вот, и последнее, что добавили, это аналайзер, который проверяет, как вы используете атрибуты authorize и allowAnonymous на ваших контроллерах, методах и так далее, потому что есть такая штука, что если вы используете, например, на контроллере authorize, а на методе используете allowAnonymous, то все хорошо, все методы контроллера будут требовать авторизации, кроме того метода, который помечен как allowAnonymous, но если вы сделаете наоборот, то есть вы контроллером напишите allowAnonymous, а на методе поставите authorize, то это работать не будет, этот метод все равно будет доступен анонимно, то есть allowAnonymous, он типа всех побеждает и как бы точно разрешает все всем детям. Вот, теперь есть аналайзер, который это засечет и скажет, вот тут что-то делаете не то, проверьте.
2043.28 2048.80 "Игорь Лабутин" Вот, собственно, все в превью. Много важных фич?
2048.80 2051.64 "Анатолий Кулаков" Ну, нормально, нет, фич много, важных нет.
2051.64 2060.60 "Игорь Лабутин" Ну, вот как есть, как есть. Ну, я специально опустил все про C# 13, про него у нас отдельная статья, но там тоже не так много, прямо скажем.
2060.60 2083.40 "Анатолий Кулаков" Давай, не то самое, чтобы C# 13, ты пока отдохни, а мы немножко тогда обсудим, что у нас не то чтобы новенького, но старенького есть в наших фреймворках, мы же не только новостной подкаст, но еще и образовательный, будем образовываться над тем, что уже есть. Хочется с вами поговорить про неизменяемые коллекции, которые у нас уже существуют в дотнете. Почему это вообще важно?
2083.40 2135.92 "Анатолий Кулаков" Ну, вообще концепция неизменяемых коллекций или неизменяемых структур данных, она очень популярная, она очень мощная, очень интересная, и многие языки программирования даже выпускаются с поддержкой в первую очередь неизменяемых коллекций. Например, все функциональные языки предпочитают работать именно с неизменяемыми коллекциями, и у некоторых вообще нет меню табельных, у некоторых они сделаны через костыль ом каким-нибудь. В общем, но языки с полностью неизменяемыми структурами данных существуют и показывают себя очень-очень эффективно во многих кейсах. Вот почему нужно как можно чаще использовать у себя в языках, даже в языке, в таком вроде мьютабельном языке, как можно чаще надо использовать неизменяемые структуры данных, потому что они дают кучу бенефитов. Вот, давайте теперь посмотрим, а что в дотнете для этого есть. Мы, естественно, не будем рассматривать все неизменяемые структуры данных, мы остановимся на нескольких самых популярных.
2135.92 2206.16 "Анатолий Кулаков" В частности, мы проанализируем, чем отличаются друг от друга read-only структуры данных, immutable и frozen. Некоторые у нас появились довольно давно, такие, как read-only, immutable появились немножко позже, а frozen это вообще свежак и может быть не каждый разработчик еще с ним успел поработать. Ну, тем полезнее будет эта статья, про которую мы с вами сегодня и поговорим. Так, прежде всего, давайте начнем с read-only. Ну, все вы можете представить какой-нибудь лист, который мы можем сложить, там, кучу каких-то интов и создать его. Я думаю, каждый день любой разработчик такие листы создает с каким-нибудь содержимым. Как нам из обычного листа получить read-only лист? Все очень просто, нужно вызвать метод as_readonly. И он нам вернет специальный read-only лист. Тот объект, который нам вернет, на самом деле является всего лишь проекцией оригинальной коллекции, оригинального листа. Что это значит? Что если мы в оригинальный лист добавим какой-то элемент, то в проекции мы этот элемент также увидим. Несмотря на то, что мы владеем каким-то read-only листом, этот read-only лист у нас может поменяться. У нас, например, как у какого-то метода.
2206.16 2211.32 "Анатолий Кулаков" И в этом есть очень большое заблуждение многих разработчиков.
2211.32 2257.48 "Анатолий Кулаков" Многие разработчики, когда в методе получают iread-only лист какой-нибудь или iread-only collection, или iread-only dictionary, они считают, что это тот лист, который никогда не поменяется. Это не так. Это тот лист, который вы никогда не можете поменять как метод. Но тот человек или тот оператор, тот кусок кода, который владеет оригинальным листом, из которого он был построен, легко может изменить содержимое вашего read-only листа. Это нужно иметь в виду. В большинстве случаев этот факт не важен, но во многих очень даже важен. Например, если мы делаем какую-нибудь параллельную обработку элементов или рассчитываем на то, что элементы никогда не законфликтуют или предрасчитываем какой-нибудь хэш и рассчитываем на то, что он всегда будет стабильным. Это не так.
2257.48 2276.72 "Анатолий Кулаков" Ну и как я уже сказал, что если у вас есть референс этого read-only листа или read-only dictionary, то сами вы его поменять не можете. Поменяться может только тот, кто обладает источником оригинальной коллекции, из которой он был построен. Это самый старый, наверное, способ использовать неизменяемые структуры у нас в дот-нете.
2276.72 2323.12 "Анатолий Кулаков" Потом попозже появилась такая прекрасная штука как immutable. Наверное, самый главный использователь immutable это была Roslyn Commando, и именно она выделила отдельную библиотеку с immutable структурами. Именно она популяризовала этот подход в C# именно. В других языках, естественно, это в функциональных особенно. Это все и так было уже на гора. Для того, чтобы из обычного листа получить immutable лист, достаточно вызвать метод расширения to immutable list. Как ни парадоксально. Эта штука создает вам тоже некую структуру, которая очень хорошо подходит для потока безопасных модификаций. Самая большая проблема у нас в параллельном конкурентном коде в том, что могут быть некие модификации, которые приводят к абсолютно или непредсказуемым ошибкам или сразу к каким-то исключениям.
2323.12 2347.64 "Анатолий Кулаков" В общем, с помощью immutable листа, immutable структуру в общем, эта проблема более-менее решается. Потому что на каждую модификацию immutable структура создает свою собственную копию. И поэтому вы даже параллельно можете обращаться и модифицировать некий dictionary, лист, и каждая параллельная операция будет работать просто-напросто со своей копией. И поэтому такие штуки довольно безопасны.
2347.64 2354.24 "Анатолий Кулаков" Вот, например, рослин. Он может анализировать ваш исходный файл и анализирует во много-много потоков.
2354.24 2375.28 "Анатолий Кулаков" И вы даже в этот момент можете этот файл менять и даже что-то вставлять. И он продолжает это анализировать во много потоков. Вот чтобы справиться с такой катавасикой, редактор редактирует, а сам анализатор в несколько потоков пытается это все разобрать в синтаксическое дерево и при этом не ошибиться и не упасть. Вот он как раз построен весь на иммьютабельных структурах данных.
2375.28 2391.44 "Анатолий Кулаков" Когда мы создаем иммьютабельную структуру непосредственно например из листа, то у нас в этот же момент порождается уже иммьютабельный лист. Что это значит? Что как бы вы сильно не изменяли лист оригинал, из которого мы породились, иммьютабельный лист никак не пострадает.
2391.44 2453.24 "Анатолий Кулаков" Он никаким образом не изменится. Вообще он никогда не меняется после того, как был создан. Несмотря на то, что методы например add, remove, clear и прочие модификационные методы у него есть. Но на самом деле, если вы его хоть раз создали, он не поменяется. Это достигается с помощью нехитрой магии. Как только вы вызываете методы модификаторы, все методы модификаторы просто-напросто берут старый лист, изменяют его содержимое и измененное содержимое вкладывают в новый лист. То есть по сути создают новую структуру данных с полной копией, за исключением выполненной операции, из оригинального листа. Поэтому оригинальный лист продолжает существовать в своей изначальном виде, а та структура данных, которая получилась в результате обработки, в результате модификации, просто-напросто живет своей собственной жизнью. Вам может на первый взгляд показаться, что это безумно расточительно как бы на каждое добавление допустим к листу создавать новый лист. Представьте у вас лист из тысячи элементов, вы добавили тысячу первой и у вас что, будет два листа и каждый по тысяче элементов? На самом деле нет. На самом деле все работает естественно намного хитрее и интереснее.
2453.24 2487.40 "Анатолий Кулаков" Внутри у себя все метаболические структуры используют АВЛ-дерево и шарят его между инстанциями в специальный шарит памяти, даже шарит в структурах. И это помогает им как раз-таки избежать дублирования в своих копиях тех данных, которые уже есть в предыдущей копии. Например, в моем примере, когда мы к тысяче элементам добавляем тысячу первой, первые тысячи элементов будут использоваться между двумя инстанциями, а второй инстанц просто-напросто будет держать ссылочку всего лишь на тысячу первой.
2487.40 2543.60 "Анатолий Кулаков" Вот и все. Поэтому второй инстанц не займет размера столько же, сколько и первый, потому что он будет переузывать как раз расшаренные структуры данных от первого. Это позволяет довольно быстро делать так называемое копирование, создание копии из изменения данных. Потому что на самом деле никакое создание копии не происходит. На самом деле мы просто ссылочку копируем на старое дерево и все. Поэтому у иммьютабельных структур создание копии и модификация происходит очень-очень быстро. Но так как под капотом там используется сложное дерево, медленно происходит чтение, операция чтения у иммьютабельных структур. Как это решить, мы посмотрим дальше. А перед этим хотелось бы минутка истории. AVL-дерево, которое как раз используется для расшаривания данных в иммьютабельных структурах данных. Что это такое? Чуть поподробнее.
2543.60 2565.80 "Анатолий Кулаков" Это self-balancing binary search tree. Так, как это можно? Самобалансируемое двоичное дерево поиска. Интересно оно тем, что было изобретено советскими учеными Георгием Максимовичем Адельсон Вельским и Евгением Михайловичем Ландис. Очень популярные ученые в математике, физике и в компьютер-сайнсе.
2565.80 2570.66 "Анатолий Кулаков" И опубликовали они пейперс этой структуры в 1962 году.
2570.66 2674.54 "Анатолий Кулаков" И это считается самым старейшим алгоритмом, который рассказывает нам про самобалансируемое бинарное дерево поиска, как структуру данных. Вот такой самый старейший алгоритм, самое старейшее дерево у нас используется в самом современнейшем дот-нет фреймворке. Теперь давайте попробуем сравнить. Да, я уже сказал, что копирование, ну по сути как бы модификация иммьютабельных структур очень быстрая. Если посмотреть на бенчмарках. Допустим, напишем два бенчмарка, у которых мы просто-напросто зададим лист из 10 тысяч элементов. И пройдемся по каждому элементу и добавим еще один элемент. То есть по сути скопируем этот иммьютабельный сет, добавим еще один элемент к этому иммьютабельному сету и сэмулируем точно такое же поведение, но на обычном хэш-сете. То есть мы хэш-сет создадим новый и в этот новый хэш-сет добавим еще один элемент. То есть проэмулируем то, что делается под капотом. Создание новой структуры данных плюс добавление одного элемента на хэш-сете и то же самое сделаем на иммьютабельном сете. Если мы такой фокус провернем, то мы увидим, что на хэш-сете это примерно занимает 94 миллисекунды, а на иммьютабельном сете 4 миллисекунды. То есть вы можете понять, что на самом деле насколько иммьютабельные структуры данных могут быстро создаваться и копировать внутри себя данные, на самом деле переиспользовать. Вот это дерево как раз и дает то, что мы экономим 95% всего того перформанса, который могли бы тратить, если бы на самом деле создавали новую структуру данных и копировали бы туда данные.
2674.54 2690.90 "Анатолий Кулаков" Но настолько быстро имеет иммьютабельный сет создаваться и модифицироваться. Теперь перейдем к нашему третьему герою, это Frozen коллекции. Они появились совсем недавно, наверняка многие из вас их даже не использовали, поэтому остановимся поподробнее.
2690.90 2694.86 "Анатолий Кулаков" Зачем нам нужны Frozen коллекции? Да и вообще, что это такое?
2694.86 2709.26 "Анатолий Кулаков" Чтобы получить Frozen коллекцию, достаточно на обычном листе вызвать метод toFrozenSet. Да, нужно сразу упомянуть, что никакого Frozen листа не существует. Бывают Frozen Set и Frozen Dictionary. Зачем эти штуки появились?
2709.26 2803.62 "Анатолий Кулаков" Ну прежде всего, как я вам раньше сказал, что иммьютабельные коллекции очень хорошо умеют модифицироваться, создаваться очень быстро, но из них очень медленно читается различные данные. И это довольно критическая вещь на самом деле, потому что мы намного чаще читаем данные, чем записываем. В такой повседневной жизни, в частных случаях. Поэтому был выработан целый концепт Frozen структур данных. Они как раз построены на той концепции, что они делают быстрое чтение и быстрый поиск. Эти структуры данных находятся в Namespace, который называется System Collection Frozen, и первые переводы были введены в .NET восьмом, поэтому если вы их ищете где-то раньше, то не рассчитывайте, не найдете. Их основная концепция заключается в том, что мы можем потратить больше времени на создание этой структуры, но при этом мы заплатим тем, то есть мы заплатим большим временем создания, но при этом получим то, что мы сможем быстрее читать из этих структур. То есть потратим больше времени на создание и получим ускоренное чтение. Это основывается на том концепции, что создаем мы обычные структуры очень редко, а вот читаем из них очень часто. Если у вас именно такая ситуация, то посмотрите на Frozen структуры, скорее всего это именно то, что вам нужно, которые создаются единожды, а потом много-много раз читаются. Давайте примерно прикинем обычный дикшеннер, если мы возьмем, например, и начнем из него читать.
2803.62 2882.58 "Анатолий Кулаков" Насколько это быстро? Давайте напишем бичмарк и сравним это с другими нашими дикшеннерами, которые уже есть. Опять же берем 10 тысяч элементов и по этим 10 тысяч элементам по всем начинаем читать. Если мы читаем обычный дикшеннер, то это примерно занимает 46 наносекунд. Если мы возьмем наш immutable дикшеннер и начнем читать из него, то это занимает уже 388 наносекунд. То есть разница с обычным дикшеннером довольно существенная. Как раз потому, что мы идем читать не просто в какие-то массивы с лукапами, хэшей, а лазим по полноценному бинарному дереву. И в immutable дикшенере в этом плане довольно медленный. А вот если мы все это сохраним в frozen дикшенере, то мы получаем 25 наносекунд на чтение. Я напомню, что у обычного дикшенера это 46 наносекунд было. То есть это примерно в два раза быстрее, чем обычный дикшенер. Какой же магией эта штука может добиваться таких интересных оптимизаций? Казалось, что обычный наш дикшенер, если кто-то лазил внутрь или задавал собеседование и их спрашивали, как устроен дикшенер, он должен понимать, что дикшенер - это довольно прямая, быстрая, а не менее мега-оптимизированная структура. Там всего лишь навсего, как бы надо заглянуть в массивчики и всё. Как можно ускорить дикшенер в два раза на пустом месте?
2882.58 2899.22 "Анатолий Кулаков" На самом деле очень сложно. И в методе toFrozenSet, например, или в toFrozenDictionary происходит очень много магии и анализа тех данных, которые содержатся внутри оригинального источника.
2899.22 2919.34 "Анатолий Кулаков" На основании этого анализа выбирается оптимальный алгоритм имплементатора. То есть, сделав два раза toFrozenSet на разных данных, вы в итоге можете получить две абсолютно разных структуры данных, которые оптимизированы под чтение именно того набора, которого им передали.
2919.34 3114.02 "Анатолий Кулаков" То есть они не смотрят на саму структуру, они анализируют именно ключи, то есть именно то, что вы им отдали. Парочку примеров. Вот если мы даже сузим до такого узкого сценария, как в ваш дикшенере, которым ключом являются строки, и эти строки в ORDINAR или в ORDINAR IGNORE CASE стратегии, что он может сделать? Во-первых, он может считать хэш по длине ключей. Действительно, длина у строки вычисляется намного быстрее, чем её хэш. И если у вас в дикшенере все ключи разной длины, то никакого смысла считать хэши нет. Мы просто-напросто посчитаем длину ключей и к каждой длине привяжем значение. Таким образом, мы получаем гораздо более эффективный алгоритм поиска элемента. Другой пример. Если мы, например, используем ключи очень одинаковые, например, в ORDINAR ключах есть ITEM1, ITEM2, ITEM3, ITEM4, ITEM5 и так далее. Строчки с такими названиями, строковыми, то их сравнение этих ключей, в случае, если у нас будет хэш коллижн, их сравнение будет довольно медленным, потому что мы будем сравнивать слово ITEM, у всех оно будет одинаковым и только последняя циферка будет отличаться. Вот эта frozen сволочь, она умеет такие случаи понимать. Она отбросит у ключей тот префикс, который будет повторяться. То есть, по сути, она возьмет только последнюю циферку. 1, 2, 3, 4, 7, 5, 6, 7, 8 и так далее. И от этой последней циферки она будет считать хэш и от этой последней циферки она будет делать компар. То есть, она выкинет у ключей первоначальный префикс, который повторяется. Ну, потому что ей для функционирования этот префикс не нужен. Он не дает никакой полезной оптимизации. Вот так, например, можно ускорить поиск. Есть еще ASCII-based хэширование и оптимизация. Если, например, она анализирует и смотрит, что там только ASCII-символы находятся, то для них применяется такой более оптимальный алгоритм. Она уже не учитывает какие-нибудь локализации и прочие Unicodes. Еще один интересный пример – это использование case-sensitive хэширования на case-insensitive данных. Как такое вообще возможно? Вот, допустим, вы создали dictionary и говорите, что у меня стратегия сравнения, она case-sensitive. То есть, мы должны сравнивать обязательно без учета регистра. Что это значит? Это по сути значит, что хэш считать от таких структур очень сложно. То есть, вам нужны эти строки, например, эти ключи привезти в какой-нибудь uppercase и посчитать хэш или еще как-нибудь вымудриться запустить специальные Unicode алгоритмы. Ну, в общем, это не так просто, как сравнивать, допустим, case-sensitive данные, у которых никаких трансформаций делать не нужно. Просто бери хэш и считай. Ну, и с компаром, то есть, со сравнением, та же самая проблема и те же самые бенефиты. А если вдруг этот алгоритм обнаруживает, что вы хотите dictionary со стратегией case-sensitive, иногда он может понять, что вы на самом деле этого не хотите.
3114.02 3123.46 "Анатолий Кулаков" Когда это может быть? Например, что несмотря на стратегию, по факту в dictionary лежат, допустим, только ключи, состоящие только из одних цифр. И все. Там нет букв.
3123.46 3159.06 "Анатолий Кулаков" А раз там только одни цифры, то на case-sensitive стратегию сравнение можно просто-напросто забить. И поэтому он специально включает case-sensitive стратегию. И, естественно, очень сильно возрастает скорость поиска и чтения из-за этого. В общем, вот такие мега-хитрые оптимизации, до которых еще додуматься надо. Эта штука делает фронтами. В тот момент, когда вы как раз создаете только frozen структуру данных. Именно поэтому создание frozen структуры данных намного тяжелее и намного медленнее, чем создание всех остальных.
3159.06 3194.66 "Анатолий Кулаков" Но зато по перформансу им нет равных. Поэтому тоже имеет смысл рассмотреть, опять же, в зависимости от ваших потребностей. Вот такие основные три у нас направления. Это read-only, всего лишь на все представление над оригинальной коллекцией. Это immutable, полностью копируемая структура данных, безопасная для конкурентных изменений в несколько потоков. И frozen, структура, которая оптимизирована для чтения, но при этом вы тратите время при ее создании.
3194.66 3216.36 "Анатолий Кулаков" Поэтому вы должны очень хорошо у них ориентироваться, чтобы каждому конкретному своему алгоритму, каждому конкретному методу понимать, что для них наиболее оптимально и какие структуры нужно использовать. Естественно, используйте больше неизменяемых структур данных, и при этом ваш код будет легче дебажиться, лучше читаться и вообще станет шелковистым и белоснежным.
3216.36 3227.18 "Игорь Лабутин" Что-то как-то, терак, послушаешь все, думать надо опять, что-то выбирать, для каждого случая решать, какое лучше, какое хуже. Нельзя там все время одно и то же использовать?
3227.18 3235.32 "Анатолий Кулаков" Ну, наверное, можно, но, опять же, тогда ты будешь ограничен. Если ты везде будешь использовать, допустим, только дикшенери, то ты должен сам себя ограничить.
3235.32 3263.46 "Анатолий Кулаков" Никаких параллельных изменений, никаких изменений стейта в вызывающем методе, никаких там, не знаю, еще чего-нибудь там. Не ложи туда то, чего класть не стоит. В общем, если ты мега умный разработчик, и ты единственный владеешь своим кодом, и ты четко сам с собой договорился, и, может быть, лучше даже скорее записал какие-то определенные договоренности, тогда, наверное, можно. Но если ты хочешь, чтобы твой код читали другие люди и случайно его не сломал какой-нибудь пришедший внезапно в команду новый разработчик, то тогда нельзя,
3263.46 3266.54 "Игорь Лабутин" тогда все равно надо думать. Ну ладно, придется думать.
3266.54 3281.70 "Игорь Лабутин" А пока давай пойдем дальше. Дальше у нас тот кусочек, который я обещал. Это C# 13. Вышла статья. Она не то, чтобы относится непосредственно к превью, она просто в целом про все апдейты, которые есть в C# 13 на текущий момент.
3281.70 3314.84 "Игорь Лабутин" Но на самом деле, мне кажется, все-таки не все. Мы же, по-моему, обсуждали фичу под названием Field Keyword, да? Когда ты теперь можешь не создавать private поля. Да, обсуждали. Обсуждали, но вот и Params Collection обсуждали, что можно теперь в парамсах использовать всякие там Arrayed Only. А, или, наверное, обсуждали по результатам билда, но мы этого не видели в реальном превью. Вот, короче, теперь все это есть, значит, давайте по порядку пробежимся. Если где-то что-то повторимся, ну, значит, повторимся, заодно получше запомните. И будем надеяться, что это не выкинуто из релиза.
3314.84 3324.98 "Игорь Лабутин" А то запоминали зря. Итак, значит, что у нас есть на текущий момент? Точно известно, что в шестом превью доступно.
3324.98 3340.82 "Игорь Лабутин" Не факт, что это останется доступным к релизу. Первое — это Params Collections. До текущего момента в C# в целом всегда можно было передать специальное, с помощью, точнее, ключевого слова Params. Можно было последний аргумент объявить массивом.
3340.82 3386.32 "Игорь Лабутин" Обычно объявляли массивом объектов, и тогда вместе вы можете записать сколько угодно аргументов через запятую, и они все забоксятся, если это вдруг value типы, и аккуратненько сложатся в массив, который вы сможете разобрать. Таким образом передавали произвольное число параметров. Но это все очень неэффективно, потому что a) боксинг, b) создание массива обязательно, даже если вы передали туда ничего, это все равно пустой массив создавался. Поэтому теперь у нас есть вариант туда написать все, что угодно, что может быть коллекционом, туда можно писать list, innumerable, какой-нибудь read-only span, что хотите, туда можно записать, и, соответственно, компилятор выберет нужную штуку, максимально оптимальную. То есть, если доступна опция с read-only span, будет выбран read-only span.
3386.32 3466.16 "Игорь Лабутин" Будет быстрее просто от перекомпиляции под новый target. Вторая вещь — это log object. Тоже, наверное, паттерн, который всем известен. Объявляем какое-нибудь private, read-only поле. Обычно его называют как-нибудь log или log object, или еще как-нибудь в таком духе, или sync object, иногда встречал. И на нем делается log. То есть, в целом работает. Log мы можем делать, напомню, на любом объекте в C#. В принципе, даже на любом value type он забоксится, пользует это никакой, но технически, по-моему, компилятор не запрещает. Теперь у нас есть новый тип, называется system-threading-log. Ведет он себя пока абсолютно так же, но в будущем есть надежда, что он будет вести себя более оптимально, более быстро, и планы на то, чтобы со временем сделать его, так сказать, основным механизмом работы с логами в будущем C#. Дальше. Если вы пользуетесь инициализаторами, это object-initializer точнее, это штука, которая позволяет вам заинтеллизировать, например, список в таком object-style инициализаторе, но через квадратные скобки вы там можете написать квадратные скобки от 0, квадратные скобки от 1. Раньше там можно было писать только порядковый индекс, теперь можно индексировать с конца с помощью крышечек.
3466.16 3523.64 "Игорь Лабутин" Крышечка 1, крышечка 2 и так далее. Но если вы хотите заполнить, например, в таком списке первый и последний элемент, в принципе, будет удобно. Добавили новый escape sequence. Напомню, escape sequence — это штуки, которые в строке начинаются с backslash. Там всякие slasher, slashen, все знают, да? Вот теперь есть slashe. Это escape sequence, раньше нужно было писать /u001b, это его ASCII код. На самом деле практическая польза есть, если вы много работаете с терминалами, потому что с терминалами, как известно, escape sequence — это основной способ всякой разной цвета там делать, вот это все. Поэтому теперь можно использовать backslash e. Partial properties я сегодня уже упоминал. Помимо partial методов, у нас теперь есть partial property. Все работает так же, как обычно, использованное, ну, точнее, придуманное в основном для source генераторов и для чего еще. Для метод групп... метод групп... блин, как это по-русски-то склонить?
3523.64 3552.40 "Игорь Лабутин" Для групп методов? Ну, короче, то, что называется метод групп — это когда вы используете имя функции без скобок, передавая ее куда-нибудь, в качестве делегата, лямта или еще чего-нибудь. Это называется метод групп, и в этом случае компилятор должен вывести какой-то тип, ну, или понять, совместим ли тип, передаваемый метод группы с тем, куда вы ее передаете. Вот теперь он выводит чуть более оптимально. Я, честно говоря, не понял, что же там поменяли, хотя честно пытался понять.
3552.40 3577.16 "Игорь Лабутин" Потому что фраза звучит так, что в C# 13 мы пересмотрели правила для того, чтобы определять, так сказать, тот самый natural type, ну, естественный тип для этого выражения, для того, чтобы убирать кандидатов, которые не имеют шансов быть выбранными. Ну, если они не имеют шансов, не нафига их убирать, короче, или не нафига их заранее добавлять, я не понял, зачем, но видимо что-то ускорили,
3577.16 3587.88 "Анатолий Кулаков" что-то улучшили. Может, это тоже там в рантайме или в генераторах, в общем? Ну, что-то типа, ты генеришь такой код, который в рантайме, тебе метод группы точно не нужный, поэтому ты их даже в лукав вставлять
3587.88 3589.92 "Игорь Лабутин" не будешь. Ну, может быть, может быть.
3589.92 3598.64 "Игорь Лабутин" Мне кажется, это все-таки все на уровне Рослина, поэтому в рантайме не про то. Это мне все-таки больше кажется именно в фиче C#, а в фиче C# это, как правило, Рослина
3598.64 3601.60 "Анатолий Кулаков" и не клуб же. Ну, значит, генераторы.
3601.60 3609.84 "Игорь Лабутин" Ну, может быть, может быть, да, может быть. Вот следующая штука не то чтобы сильно важная, но может быть интересная.
3609.84 3654.12 "Игорь Лабутин" У нас появился еще один новый generic constraint, называется allowsRefStruct. Позволяет, собственно, рефстрактам, наверное, самый известный, это span, это объекты, точнее типы, которые могут быть аллоцированы только на стыке или на, ну, соответственно, они могут храниться в куче. Они теперь могут быть constraint в генериках. Ну, и, соответственно, такой генерик тоже становится естественно таким же. Фишка, интересное, так сказать, замечание состоит в том, что я это говорю, что добавился новый генерик constraint, хотя в реальности все остальные у нас constraint, а этот, наоборот, расширяет список типов, которые можно туда запихивать. То есть это как бы не совсем constraint, в каком-то смысле такой анти-constraint.
3654.12 3712.16 "Игорь Лабутин" Ну, тем не менее, вот, если вам зачем-то нужен был генерик тип от span, можно теперь сделать span от span, при желании, наверное. Не пробовал, кстати. И вторая тоже довольно важная штука. Ну, я не знаю, успел ли она стать вопросом на собеседование, но, может быть, вам полезно, если вы пишете какой-нибудь hyper в код. Это то, что раньше в async методах, ну, и в итераторах, которые с помощью yield, да, пишутся, нельзя было использовать ref, соответственно, на struct, и нельзя было использовать unsafe код. Никак. Теперь это делать можно. Можно использовать ref, ref-локальные переменные, можно использовать ref-структы, можно использовать unsafe, но с одним единственным "но". Эти самые переменные не должны, использование этих переменных, да, и их время жизни не должно пересекаться с точками, где вы делаете await, ну, или yield, да, если мы говорим об итераторах.
3712.16 3771.92 "Игорь Лабутин" Что, в принципе, понятно. Почему? Потому что именно в этих точках внутреннее состояние этих самых методов боксится в специальную структуру, которая уходит в heap и ждет, когда этот метод закончит работу, а в heap положителя, в struct все еще никак нельзя, ну, по понятным причинам, он может указать на stack куда угодно, поэтому, если вам зачем-то нужна какая-нибудь локальная, локальный какой-нибудь спан между двумя awaitами, чтобы быстренько что-то сделать, вызвать какую-то хайперфункцию, пожалуйста, можно использовать, но через await он не переживет, поэтому разрешили, но не до конца, но, в принципе, ограничение понятно. Ну и последний заголовок в статье, он такой очень маленький, но он очень важный, называется "Extension Types", где будет сказано, что, ну, мы что-то, короче, вам показали на билде, всем понравилось, было круто, все замечательно, но что-то мы не успеваем сделать к релизу, поэтому extension types в 13 C# не будет, ждите их в первых превьюшках
3771.92 3777.68 "Анатолий Кулаков" 14 C#. Ну и зачем они нам нужны в превьюшках? Мы их юзать
3777.68 3786.24 "Игорь Лабутин" хотим, мы не превьюить. Ну, видимо, они столкнулись с некоторыми трудностями, либо, не знаю, не успевают, либо нашли какие-то проблемы, либо что-то с кем-то не склеивается.
3786.24 3791.40 "Анатолий Кулаков" Да, они ничего не делали полгода, блин, ни одного превью нормального не было, что-то не успевают, что они
3791.40 3798.84 "Игорь Лабутин" делали все это время? Ну, как обычно, надо это, три года планировать, за последнюю неделю ничего не успеть, что это первый раз в бизнесе, что ли? Да ну сколько можно,
3798.84 3801.44 "Анатолий Кулаков" ни одного нормального релиза нету за последние два релиза.
3801.44 3805.12 "Игорь Лабутин" Готовимся к экзамену в последнюю ночь, что ты. Вот не успели,
3805.12 3810.50 "Анатолий Кулаков" не сдали. Почему не сдали они, а страдаем мы, как-то
3810.50 3827.36 "Игорь Лабутин" это неправильно. Так сложилось, да, так сложилось. Ну, короче, не будет у нас extension-ов, похоже, не будет, ну, по крайней мере, пока ничего не слышно ни про какие discriminated unions, и, видимо, 13 C# будет действительно очередным набором таких, не очень больших фич. Ну, поглядим.
3827.36 3833.80 "Игорь Лабутин" Никому не нужна унылость. Давай дальше, пойдем посмотрим что-нибудь более веселенькое, если у нас есть.
3833.80 3907.00 "Анатолий Кулаков" О, веселенького у нас полно, особенно на фоне того, что ничего в новом C# нам не светит. Ну что ж, давайте тогда продолжать разбираться со старыми структурами данных. Следующая интересная структура, про которую хотелось бы вам рассказать, это memory cache. Puppage - очень знаменитая штука, в том плане, что нужна практически всем, и почему-то мало людей о ней знают, поэтому я решил углубить и расширить. Memory cache - это стандартная имплементация, не поверите, cache в памяти для C#. Она признана как раз-таки улучшить производительность и мастерируемость вашего кода, но при этом вы можете немножко пострадать в плане памяти. Когда нужно использовать memory cache? Memory cache нужно использовать если у вас есть какой-нибудь запрос, который пожирает очень много ресурсов. Эти ресурсы могут быть как различные ресурсы - CPU ресурсы, может быть денежные ресурсы, может быть какие-нибудь сложно вычислительные алгоритмы или хождение в медленную сеть. Разные могут быть ресурсы. И при этом результат, который вы получите, его можно перегрузать после первого получения.
3907.00 3936.96 "Анатолий Кулаков" Еще признаки, про которые вам стоит рассмотреть использование in-memory кэша. Или вообще кэша в частности, необязательно in-memory. Во-первых, это небольшой размер того результата, который вы получаете, потому что если размер будет большой, то ваш кэш очень быстро забьется. Было бы неплохо, если бы размер был маленький. Следующий признак - результат работы какого-то медленного метода часто переиспользуется.
3936.96 3956.96 "Анатолий Кулаков" То есть, если вы вызовете какой-нибудь годовалый отчет раз в год, и всего один раз в год его поиспользуете, никакого смысла кэшировать нет. Но если вы его один раз построите, а потом 10 тысяч раз будете смотреть, то вот тогда уже можно рассмотреть его кэширование. Дальше ваш запрос должен быть дорогим для выполнения.
3956.96 3980.96 "Анатолий Кулаков" Как я уже сказал, дорогость, то насколько он дорог, может зависеть много от чего. Может быть CPU, memory, сеть, что угодно. Его должно быть дорого выполнять. И результат должен быть стабильным во времени. То есть, желательно, чтобы тот результат, который вы получили, он очень часто не менялся. Тогда его какой-то смысл кэшировать есть.
3980.96 4030.04 "Анатолий Кулаков" Если он часто меняется, то ваш кэш будет протухать довольно очень быстро. Ну, например, если мы используем каталог продуктов, которые есть в вашей системе, то это хороший кандидат для кэширования. Почему? Потому что он меняется довольно редко. Обычно это небольшой размер вот такого каталога. И строить его довольно сложно, потому что несколько раз нужно сходить в базу данных для того, чтобы все собрать, какие-то запросики потащить, джойны сделать. И эта операция может быть довольно долгой. С другой стороны, если мы рассмотрим, например, лист заказов, то вот этого персонажа кэшировать не стоит. Потому что обычно он может быть довольно большой, если у вас заказов довольно много.
4030.04 4042.28 "Анатолий Кулаков" И самое главное, он очень часто меняется. Если пользователь начинает по нему тыкать, добавлять новые заказы, то его очень быстро нужно будет где-то обновлять.
4042.28 4069.84 "Анатолий Кулаков" И поэтому такая структура для кэширования подходит довольно плохо. Опять же, все зависит от ситуации, от конкретной вашей реализации, от конкретной вашей программы, но в общем случае примеры вот такие. Давайте посмотрим на практический пример еще. Допустим, если у нас есть какая-то биржа курсов валют, внешняя. Она предоставляет нам свой API, а мы в нашем приложении к этому API обращаемся.
4069.84 4171.08 "Анатолий Кулаков" И создаем себе домашнюю страничку. В этой домашней страничке мы хотим показать какие-то 4 валюты. Просто-напросто их текущий курс. Что для этого нужно? Ну, прежде всего 4 раза пробежать, допустим, в фурричи по всем тем валютам, которые мы хотим отобразить. Взять HTTP Client, сгонять на удаленный API, забрать оттуда этот курс и отрендерить его у нас локально на обычной страничке. У автора данный процесс занял почти 400 миллисекунд. И каждый раз, когда вы открываете домашнюю страничку, она у вас открывается минимум за 400 миллисекунд. Это довольно медленно. Какие у этого подхода есть еще проблемы? Ну, во-первых, 400 миллисекунд – это медленно. У нас всего-навсего 4 котировки. Если мы захотим больше, то это будет расти просто линейно. Дальше у нас может быть стоимость вызова API. Так как мы используем внешний сервис, этот внешний сервис может брать какую-то стоимость за каждый вызов. Если мы зашли на нашу страничку 10 раз, то, пожалуйста, ценник умножайте на 10, потому что на каждый заход на нашу страничку идет вызов к этому внешнему сервису. Также у нас может быть стоимость какого-нибудь cloud-хостинг-решения. То есть у нас сейчас любят клауд-провайдеры брать деньги и за DNS-лукап, и за роутинг, и за каждое обращение к какому-то API, и за трафик, и за все подряд. В общем, в этом примере у нас будет довольно много всяких обращений, роутингов, трафиков. Поэтому там тоже вас могут за что-то почаржить. И прежде всего тоже есть такой минус у данного подхода – это надежность.
4171.08 4208.52 "Анатолий Кулаков" Если этот data-провайдер почему-то окажется немножко недоступен, или упадет, или закроется, или еще что-нибудь, то вся ваша домашняя страничка мгновенно превратится в тыкву. Вы не сможете посмотреть никакую из котировок, даже если вам было бы вполне актуально посмотреть на последнюю расценку этой котировки. И, в принципе, все эти проблемы способны решить memory cache. А насколько быстр этот memory cache? Сколько он нам даст преимущества по перформансу, допустим? Если коротко, то memory cache очень быстр. Как он работает, почему он добивается мега-быстроты?
4208.52 4219.64 "Анатолий Кулаков" Добивается он очень просто, потому что он сохраняет ссылку на ваш объект, который на результат работы вашего метода, он просто-напросто сохраняет у себя ссылку.
4219.64 4244.24 "Анатолий Кулаков" Функциональное сохранение ссылки имеет очень много преимуществ. Во-первых, вам не нужно это как-то маршалить, на это не тратится время, потому что маршалинг – это всегда очень медленно. И, во-вторых, он сам сообщает garbage collector, по сути, что собирать этот объект не нужно, этот объект еще может пригодиться в будущем, и поэтому вы в своем вызывающем коде можете просто-напросто про это забыть и не переживать, что объект куда-то уйдет.
4244.24 4353.76 "Анатолий Кулаков" Скорость memory cache на даже запись, чтение операциях – это измеряется в десятках наносекунд, поэтому вы этого даже и не заметите, особенно если будем сравнивать с нашим предыдущим результатом. Когда мы говорим про кэширование, всегда нужно в голове держать в альтернативу такую как Distributed Cache. Например, Redis или Memcached или другие какие-то провайдеры, которые могут вам делать распределенные кэширования. У них есть провайдеры в .NET, и вы точно также можете подключить. В чем различие in-memory кэша локального и Distributed Cache? В том, что Distributed Cache располагается на какой-то внешней машине. Это значит, что никаких ссылок на .NET объект он не содержит. Это значит, что мы должны делать тот самый маршаллинг. Обычно в Distributed Cache хранятся или бинарные данные, или текстовые данные, что-то такое. И для того, чтобы из нашего C# объекта сделать текстовые или бинарные данные, существует процесс сериализации и десериализации. Вы должны будете ваши объекты сериализовать, десериализовать, перенаправлять куда-то в сеть, на какую-то другую машину, оттуда их считывать. Это все намного медленнее, чем просто-напросто естественно хранить ссылочку в памяти и все. Но у Distributed Cache есть свои преимущества. О них мы поговорим немножко попозже. Итак, in-memory кэш. Как я уже сказал, это безумно быстрая штука. Но если мы загоняемся полностью к performance, является ли in-memory кэш самым производительной структурой, которую мы можем потреблять? Нет. На самом деле не является. In-memory кэш прекрасен тем, что у него очень хорошее соотношение между тем, какие возможности он дает по кэшированию и performance.
4353.76 4391.96 "Анатолий Кулаков" Если вы, например, никогда не удаляете ваши данные из памяти, только добавляете их туда и читаете, и все, то на самом деле concurrent dictionary от String Object будет намного быстрее in-memory кэша. И вы вполне можете использовать его. Но только помните, что если вы оттуда ничего не удаляете, то у вас может быть какой-нибудь out-of-memory exception. Поэтому четко следите за памятью, за тем, что действительно туда много не складываете. Если же вы полностью упарываетесь по performance, то рано или поздно вы столкнетесь с тем, что для in-memory кэша необходимо в качестве ключа указывать строку. И эта строка должна собираться довольно уникальной.
4391.96 4437.04 "Анатолий Кулаков" И вот в performance-critical коде вы вполне можете упираться в сборку вот этой строки, которая является ключом непосредственно для ваших данных. Поэтому в этом случае он тоже вам может не подойти. Также полезно рассмотреть в таких performance-critical вариантах использование специального класса, который называется ConditionalWigTable. Как вы, наверное, понимаете, по названию, это штука, которая оперирует свик-референсами и прочими вещами для того, чтобы сделать как раз-таки вам in-memory кэш. Какие же проблемы есть у in-memory кэша? Он не только весь из себя хороший и красивый, но и у него есть такие темные стороны. Во-первых, это рассинхронизация между несколькими приложениями.
4437.04 4447.32 "Анатолий Кулаков" В нашем мире принято запускать приложения в нескольких инстанциях, то есть на разных машинах, в разных нодах.
4447.32 4482.16 "Анатолий Кулаков" И если, допустим, вы используете in-memory кэш, то он хранится в памяти одного из процессов. И если вы закэшировали данные, то те данные, которые вы закэшировали в одном процессе вполне могут не соответствовать тем данным, которые закэшировались в другом процессе. Как такое может произойти? Допустим, обе ноды прочитали правильные валидные данные из базы данных. И затем в одну из нод пришел запрос на изменение данных. Таким образом, нода номер один эти данные у себя поменяла, в кэше их тоже обновила, и они у нее теперь свежие и красивые.
4482.16 4519.88 "Анатолий Кулаков" Но нода номер два ничего не знает ни про какие обновления данных. Она продолжает пользователю отдавать данные старые. И таким образом, в зависимости от того, куда пользователь зайдет, на первую ноду или на вторую, он может получить новые актуальные данные красивые или старые устаревшие. Вот, в принципе, вот эту проблему хорошо решает Distributed Cache. То есть, выделение кэша в отдельную машину, в которой кэш будет один для всех. Да, он может быть устаревшим, или он может быть новым, но он всегда будет консистентным для всех нод. Потому что все ноды локально его у себя не держат, они ходят в одну единственную точку. И это более-менее нивелирует данную проблему.
4519.88 4523.72 "Анатолий Кулаков" Другая проблема memory-cache это инвалидация данных.
4523.72 4566.36 "Анатолий Кулаков" Как все мы знаем, две самых больших проблемы в программировании – это придумывание названий для переменных и инвалидация кэша. В общем, здесь мы никуда от этого не ушли. После того, как некие данные изменились, те данные, которые лежат в кэше, их из кэша нужно удалить. Или каким-то другим образом пометить, что они больше не валидны, и их нужно там или обновить, или не отдавать, или что-то с ними еще сделать. И вот решение вот этой задачи, о каким образом и когда обновлять кэш, это может быть довольно нетриверальная штука. У in-memory кэша есть все необходимые методы для того, чтобы это сделать, но вот когда их вызывать – это зависит от конкретного приложения, и такие места могут быть довольно неочевидными.
4566.36 4662.44 "Анатолий Кулаков" Следующая проблема не то, чтобы in-memory кэша, просто криворуких разработчиков, но в общем сюда относятся – это опасность того, что в кэше засунут изменяемые структуры данных. Немножко пересекается с нашей первой темой. Бывают очень часто такие случаи, когда вы делаете какой-то объект, который может меняться, и засовываете его в кэш. И потом, после того, как вы этот в кэш его уже засунули, у вас процесс изменения этого объекта может продолжиться. И в этот момент его уже из кэша кто-то начнет читать. Кто-то прочитал этот объект и увидел одно поле, потом вы в параллельной может быть потоке изменили его, и уже другой читальщик увидит совсем другие значения. И многие-многие другие проблемы вас могут подстерегать, если вы используете изменяемые объекты в кэше. Просто часы и дни отладки очень больные, очень неочевидные, очень страшные отладки могут вас поджидать. Поэтому золотое правило, если вы используете кэш, то используйте его только с неизменяемыми структурами данных. Не поскупитесь на какую-то там память или еще на мнимое что-то. Отладка и бессонные ночи стоят намного дороже. Теперь давайте рассмотрим, а как же нам завязать in-memory кэш. Мы поняли, что эта штука хорошая, красивая. Давайте подключим к нашему примеру. Для этого нам нужен пакет Microsoft Extension Caching Memory, и напрямую с in-memory кэшом мы работать не будем. У него есть хорошее низкоуровневое интерфейс, которое называется i-memory кэш. Основные методы у него это создать сущность в кэше, то есть по сути положить сущность в кэш, попытаться достать сущность из кэша и удалить сущность из кэша.
4662.44 4748.40 "Анатолий Кулаков" На основании трех этих примитивов можно сделать практически все, что нам нужно. Но обычно с этими низкоуровневыми методами мы не работаем, потому что это совсем неудобно. Есть прекрасный метод расширения, который называется getOrCreate. Он наверняка вам знаком по concurrent dictionary. С ним очень удобно управляться, и поэтому в большинстве случаев используют именно его. В вашем приложении необходимо в сервисы вызвать метод addInMemoryCache, который добавит все необходимые интерфейсы. В том классе, где вы обрабатываете непосредственно вам необходимо заинжектировать, внедрить интерфейс iMemoryCache и заиспользовать его в нашем коде. Например, если рассматривать наш пример с получением котировок на курса четырех валют. Прежде чем начать получать, в InMemoryCache всегда нужно тщательно подойти к выбору ключа. Почему это так важно? Потому что если мы в качестве ключа выберем просто, например, название какой-то валюты и запишем его в кэш, нужно помнить, что этот кэш один на все ваши приложения. И совсем другой метод, который допустим эти валюты куда-нибудь конвертирует, а не просто показывает, он тоже может выбрать у себя в качестве ключа название этой валюты. И тогда ваш кэш пересечется, потрется, и опять же, годы бессонных дебагов вам обеспечены.
4748.40 4789.72 "Анатолий Кулаков" Поэтому ключом нужно выбирать достаточно уникальную строку. В общем случае, советую прямо выбирать название метода или название класса, которым вы сейчас кэшируете, и уже добавлять к этому названию класса название метода название, например, котировки. Тогда вы сможете значение этой котировки сохранить по данному ключу. Эта проблема усугубляется еще сильнее, если вы будете использовать Distributed Cache, потому что там у вас сто процентов будут разные инстансы запущенные с одним и тем же названием метода и с одним и тем же названием класса. И вот должны не пересекаться или не должны, это вам нужно смотреть в каждом конкретном случае.
4789.72 4849.80 "Анатолий Кулаков" Ну в общем, при выборе ключа во время кэширования нужно быть очень осторожным и подходить со всей ответственностью к этому процессу. После того, как мы выбрали ключ, все довольно очевидно становится. У интерфейса memory-cache мы вызываем метод getOrCreate, передаем ключ и передаем фабрику, которая будет вызываться, если вдруг такой ключ у нас в кэше отсутствует. Ну то есть, именно если ключ отсутствует, только тогда мы пойдем, например, к нашему внешнему API и запросим у него котировки. При каждом вызове этого метода у нас выполняется четкий ожидаемый набор шагов. Проверяется, есть ли ключ в кэше. Если он в кэше есть, то мы возвращаем значение из кэша. Если в кэше нет, то мы вызываем метод фабрику, которая идет куда-то, выполняет какую-то сложную операцию и результат этой сложной операции мы кладем в кэш и возвращаем к пользователю. При этом можно пользоваться и радоваться жизни. Первый запрос, который придет в наше приложение, прокрутит все наши четыре котировки и заполнит кэш.
4849.80 5047.28 "Анатолий Кулаков" А все остальные запросы будут выполняться уже на основании того кэша, который у нас есть. И в данном конкретном примере автор добился того, что его страничка вместо 400 миллисекунд, которая открывалась до этого, стала открываться всего-навсего за одну миллисекунду. Естественно, после того, как все первый запрос прокэшировал, мы все значения отдаем из памяти, из локальной, поэтому одна миллисекунда - это все, что нам нужно для того, чтобы отрендерить уже на домашнюю страничку из четырех котировок. При этом, что мы еще получили? Мы уменьшили, соответственно, время рендера домашней странички, мы уменьшили использование CPU, нам больше не нужно считать, дистерилизовать, ходить куда-то в интернет, мы просто забираем ссылку на объект из той памяти, в которой находится сам процесс. Также мы уменьшили количество API-вызовов, что косвенно может привести к сокращению каких-то стоимостей, если, допустим, API был у нас платный. Мы увеличили надежность. В этот момент, если у нас эта биржа с котировками моргнет или выключится, то у нас всегда есть значения в кэше, которые мы какое-то время можем использовать. Более-менее это может быть приемлемым вариантом. И также у нас улучшился юзер-экспириенс, потому что пользователь мгновенно видит у себя эти значения, он не ждет каждый раз, когда заходит на страничку, и, наверное, ему это должно больше понравиться. И при этом мы не сильно потеряли в памяти, потому что результат работы котировок, вот этого метода, то есть тот результат, который мы кэшируем, он довольно маленький, небольшой, поэтому, в принципе, здесь все нормально, все хорошо. Ну, все да не все, потому что, на самом деле, если мы оставим наш пример в таком виде, то сколько раз бы мы на него не зашли, котировки будут всегда показываться одни и те же. Меняться никогда они не будут. А все потому, что мы просто-напросто запихнули данные в кэш и никаким образом не обновляем эти данные. Котировки нужно постоянно обновлять. Делается это довольно просто. In-Memory кэш предоставляет огромную кучу стратегий, с помощью которых вы можете обновлять данные в кэше. То есть он их не обновляет, он их просто из кэша удаляет. Ну, например, если вы у сущности кэша вызовите метод, который называется setAbsoluteExpiration, 30 секунд, то он через 30 секунд удалит эту сущность, этот кэш, удалит из себя, и в следующий раз, когда вы обратитесь к этому кэшу, он вас просто-напросто не найдет, и поэтому пойдете и обновите это все из внешнего API. То есть каждые 30 секунд кэш у вас будет обновляться. Там существует очень много хороших алгоритмов, там есть скользящее окно, например, можно оставлять в кэше не просто через 30 секунд, а если вдруг 30 секунд вы не использовали значение этого кэша, а если бы вы в рамках окна 30 секунд этот элемент кэша использовали бы, то его срок жизни продлевался бы. Таким образом, вы можете горячие данные держать все время в кэше, а холодные данные у вас будут естественным путем удаляться. В общем, и много таких интересных алгоритмов есть. Вот чем прекрасен In-Memory Cache, и чем он отличается в основном от Dictionary. Его замечательными гибкими стратегиями удаления. Теперь, давайте посмотрим.
5047.28 5080.16 "Анатолий Кулаков" В принципе, эта картина получилась довольно хорошей за исключением момента, что мы очень сильно завязаны на In-Memory Cache. И эта завязка, она у нас непосредственно в стратегии обработки прокинута. То есть мы напрямую рассчитываем на интерфейс Memory Cache и логика получения данных напрямую завязана с тем, что мы используем In-Memory Cache. Это не очень хорошо, потому что, например, в будущем мы можем передумать и подменить In-Memory Cache на что-то другое. Ну, например, Distributed Cache. Очень частая ситуация, между прочим.
5080.16 5093.88 "Анатолий Кулаков" Поэтому здесь было бы неплохо разделить ту логику, которая у нас есть для получения данных, ту того потребителя, который читает эти данные, и непосредственно абстракции вот этого кэша. Соответственно, тем, кто управляет кэшированием.
5093.88 5160.52 "Анатолий Кулаков" Самым первым вариантом, который вам стоит рассмотреть, это библиотека Polly. Многие из вас наверняка использовали Polly для того, чтобы выдумать какую-нибудь стратегию для более надежного извлечения данных, или обработки ошибок, или ретраев, или Circle Breaker, или чего-то другого. В общем, здесь он просто жалко абсолютно всем все ухи. Но у Polly есть еще одна замечательная классика, которая называется Polly Caching Memory, которая как раз-таки и дает нам абстракцию над кэшом. И под капотом этот мемори используют Memory Cache. И под капотом вы легко очень можете переключить его на Distributed Cache. При этом все потребители, которые будут использовать абстракцию мемории от Polly, ничего даже об этом не узнают. И еще одно преимущество в том, что, естественно, этот кэш очень хорошо интегрирован со всякими полиполисями. То есть вы можете положить в кэш только ту запись, которая, допустим, вернулась самой первой из трех различных запросов, которые были отправлены параллельно, и при этом не было исключения, и при этом не было ретраев, и при этом лимит не установлен.
5160.52 5273.04 "Анатолий Кулаков" В общем, все вот эти полевские нагромождения, которые вы можете себе представить, они прекрасно дружат и с его реализацией Memory Cache. Еще одна интересная альтернатива, которую стоит рассмотреть, это Easy Caching. Easy Caching дает вам абстракцию над кэшом, но его основная фишка в другом. В отличие от Polly, он предоставляет огромное число провайдеров, данных, где вы можете кэшировать свои данные. Ну, естественно, Redis, Memcached, SQLite, обычные SQL, Postgres и много-много другое. В общем, там список довольно богатый этих провайдеров. Поэтому если вы хотите каким-то образом гибко запоминать различные источники хранения информации и писать в них, Easy Caching вполне может вам подойти. Также нужно не забывать, что при релизе у нас там готовится гибрид кэш. Это такой мостик между Distributed Cache и Memory Cache. Эта реализация нам позволяет в определенные моменты времени хранить определенные данные в Distributed Cache, а горячие, например, холодные данные в Distributed Cache, а горячие данные, например, в Memory Cache. В общем, тут тоже стоит, может, ими поиграться. Кстати, Easy Caching в качестве одного из провайдеров умеет поддерживать как раз уже гибрид кэш. И, наверное, последний метод, который позволяет вам избежать вот этого Blueprint кода – это использование металламы. Мы ее обсуждали как раз на прошлом подкасте, и эта статья тоже навеяна блогами металламы. Естественно, она хочет себя порекламировать, но она действительно предлагает очень хорошее и качественное решение по сравнению со всеми остальными. Потому что каким бы образом вы не абстрагировали вот этот слой, как бы вы хоть через поле, хоть через какую-то другую абстракцию, что бы вы там ни делали, вам в любом случае, в каком-то месте нужно будет их скрестить.
5273.04 5309.64 "Анатолий Кулаков" Вам нужно будет взять какой-нибудь iMemory, вам нужно взять какой-нибудь вызов HTTP-клайента и где-то показать, что вот этот HTTP-клайнт вызывается и складывает свой результат в этот Memory Cache. В общем, от этой связки вы не избавитесь. Можете сделать его красивее, но избавиться никак. И вот как раз металлама предлагает вам нормальное, вполне хорошее избавление. Потому что кэширование – это чистый паттерн аспектного программирования. Для чего, собственно, металлама и создавалась? Как это работает? Вы просто-напросто в том методе, который вас из HTTP-клайнта возвращает к котировке, на нем ставите атрибут, который называется кэш.
5309.64 5313.24 "Анатолий Кулаков" И этот атрибут кэш, например, может принимать expiration time.
5313.24 5319.16 "Анатолий Кулаков" Например, expiration time, допустим, 30 минут. И все. Это все, что вам нужно. Все остальное металлама сделает сама.
5319.16 5349.96 "Анатолий Кулаков" Она сама вызовет HTTP-клайнт, когда это необходимо, сама закэширует результат и сама его почистит, когда истечет указанное время. Опять же, у металлама очень много минусов. Скорее всего, использовать вы ее не будете, но как пример использования аспектно-ориентированного программирования, в общем, вы должны знать, что так можно делать. В общем, на этом погружение в Memory Cache заканчивается. Если вы вдруг никогда не слышали про такой класс, то обязательно на него посмотрите и заиспользуйте.
5349.96 5355.28 "Анатолий Кулаков" А если слышали, то, может быть, открыли для себя какие-то новые аспекты и какой-то новый способ использования,
5355.28 5401.24 "Игорь Лабутин" к которым раньше не прибегали. Ну, да, кэширование — тема важная. Без нее никуда, в каком-то смысле, по-моему, если не в каждом, но вот у нас, наверное, в половине приложений в каком-то виде какое-то кэширование где-то есть. Пусть даже хотя бы в виде того самого concurrent dictionary, но уже пригождается, бывает. Действительно, если есть вероятность, что ваш кэш потребуется делать раз на… Как это сказать? Распределенным, вот, вспомнил слово, то лучше заиспользовать что-то более стандартно готовое, стороннее, такое вот а-ля easy caching или что-то такое, чтобы вы могли потом это дело заменить на distributed, когда потребуется. Это как с базой данных. Да, используя кэш, чтобы иметь возможность заменить базу данных. Вот.
5401.24 5409.24 "Игорь Лабутин" Да, да, именно так. Ну, ладно, давай пойдем сегодня на последнюю тему. У нас осталась маленькая последняя темка.
5409.24 5429.54 "Игорь Лабутин" Сейчас я ее достану из backlog'а. Вот она. Это Visual Studio Preview 3. Естественно, обычно вместе со всякими C#'ами, превьюшками и прочим выходит соответствующая версия превью. Как ни странно, в этот раз в превью нет практически ничего такого интересненького.
5429.54 5476.20 "Игорь Лабутин" Там буквально пара фич про productivity. В основном это касается кодленсов. Там немножко пофиксили, значит, то, как кодленсы работают. И в pull request creation, то есть когда вы создаете pull request прямо из Visual Studio, там добавилось некоторое количество улучшалок. Типа, например, теперь можно выбрать target branch. Это как-то для меня странно, потому что когда я создаю pull request, я, как правило, хочу указать, к какому branch'у я pull request делаю. Ну вот, теперь можно выбрать. А также... Видимо, ты не всегда должен этого хотеть. Ну нет, понятно, что в принципе можно найти общего ближайшего предка. И если этот общий предок содержится всего в двух branch'ах, то, наверное, я хочу pull request из моего branch'а в другой branch. Но иногда этот общий предок содержится больше, чем в двух branch'ах.
5476.20 5512.16 "Игорь Лабутин" И тогда вот начинаются вопросы. В какой же branch'е я хочу мержить этот самый pull request? Ну, видимо, действительно сначала поддержали простейшесть, а теперь расширяют. Причем забавно тоже написано. Написано, что мы добавили target branch selection, commit counts, то есть раньше нельзя было посмотреть, сколько коммитов у тебя в pull request при создании, видимо, в окошке создания. А также other stabilization fixes, что как бы для меня переводится как, ну да, добавили выборы ветки, количество коммитов и другие фиксы про стабилизацию.
5512.16 5515.68 "Игорь Лабутин" Хотя первые два явно не про стабилизацию. Ну ладно.
5515.68 5532.00 "Игорь Лабутин" Ну и автоматическое создание линков на те work-items, которые вы упомянули в описании. Ну и GitHub Copilot. Как ты помнишь, ты чуть-чуть раньше сегодня говорил, давайте мы уже в IntelliSense запишем там, занесем автогенерацию документации.
5532.00 5564.32 "Игорь Лабутин" Вот мы уже где-то там. Теперь в GitHub Copilot, если вы им пользуетесь, вот теперь если вы наводите мышку на курсорчик, чтобы появился вот этот tooltip, где написано, что же за метод под курсором стоит, там теперь можно сказать "tell me more", нажать кнопочку, я понимаю, и тогда Copilot включится и значит вам нагенерит описание, что же он видит в этом коде, и что он может сказать про тот метод, на котором вы сейчас стоите, вызываемый. То есть такое типа документацию
5564.32 5574.20 "Анатолий Кулаков" автоматически сгенерит вам. Ну вот это хорошо. Просто мне, наверное, не хочется по кнопочке бы нажимать, могли бы там пригенерить заранее, это поддерживать в актуальном состоянии, да и все. Видимо, слишком
5574.20 5633.20 "Игорь Лабутин" много, потому что, а дальше есть еще следующая кнопочка, типа перейти в чат, и тогда ты сможешь уже в чате как-то более детально пообщаться в чат режиме на тему этого кода, метода и так далее. Кроме того, добавили, если вы вдруг пользуетесь GitHub Copilot или не пользуетесь, потому что боитесь там вопросов секьюрити, ну не то, что боитесь, а у вас есть вопросы по секьюрити, теперь можно выбрать солюшены или файлы конкретные, которые ни в коем случае GitHub Copilot трогать не должен. И типа их не использует, ну в смысле, в них он тогда заглядывать не будет и никуда их подсылать не будет. Вот. Ну в общем-то и все, вот и все, что появилось в третьем превью Visual Studio. В C# изменений нет, поэтому, видимо, в компиляторе ничего менять не надо, и поэтому в студии особых каких-то больших нововведений нету. Ну вот как-то и все. Кратка о разном сегодня тоже нету, что-то каких-то статей коротеньких и интересных ссылок не попалось. Поэтому на сегодня я думаю, что мы можем заканчивать. Да, давай закругляться.
5633.20 5689.44 "Игорь Лабутин" Давай закругляться, превью 6 вышел, мы его обсудили, поговорили про read-only, immutable и frozen коллекции, чем они все отличаются, чем могут быть полезны, когда какие использовать, ну правильный ответ думайте. Посмотрели на текущее состояние C# 13, попереживали, что похоже к релизу не успеется ничего супербольшого и важного родиться, посмотрим. Подробнейшим образом поговорили про memory cache класс и про то вообще как подходить к кэшированию в дотнете, что можно использовать и какие рекомендации есть на этот счет. Ну и посмотрели на совсем кратенько превью 3, очередной Visual Studio. Тоже ничего особо интересного, ждем чего-нибудь более существенного. Например, релиз. Нет ну релиз понятно в ноябре будет, но что-то я, ну смотри, согласись, что по сравнению с вот в прошлом ноябре, когда релизился прошлый дотнет, в общем-то Aspire же даже только
5689.44 5693.32 "Анатолий Кулаков" показали. Ну да, с чего можно было поговорить это Aspire.
5693.32 5709.72 "Игорь Лабутин" Вот, потому что все остальное в принципе было уже известно на момент как бы релиза, все остальное в превью так или иначе светилось. Поэтому, ну вот может быть там будет какой-нибудь Aspire номер 2, секретный проект, опять это, на год. Всех, значит, заинтересует, посмотрим,
5709.72 5729.64 "Анатолий Кулаков" посмотрим. Да, будем внимательно следить и вы тоже, если подпишетесь на наш подкастик, то обязательно не пропустите никаких новых интересных нововведений во фреймворк. Ну что ж, если еще не подписались, подписывайтесь, комментарии оставляйте, друзей зовите, подкастик всем кидайте и до следующих встреч. Всем пока.
5729.64 5730.36 "Игорь Лабутин" Всем пока.
